#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•predictions.csvå¢å¼ºåŠŸèƒ½
"""

import pandas as pd
import numpy as np
from pathlib import Path

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("ğŸ”§ åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•
    test_data_dir = Path('./test_data')
    test_data_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿçš„å®Œæ•´è‚¡ç¥¨æ•°æ®
    np.random.seed(42)
    n_samples = 1000
    n_features = 20
    
    # è‚¡ç¥¨ä»£ç åˆ—è¡¨
    stock_codes = [f"{i:06d}.SZ" for i in range(1, 51)] * 20  # 50åªè‚¡ç¥¨ï¼Œæ¯åª20å¤©æ•°æ®
    
    # è‚¡ç¥¨åç§°åˆ—è¡¨
    stock_names = [f"è‚¡ç¥¨{i}" for i in range(1, 51)] * 20
    
    # æ—¥æœŸåˆ—è¡¨
    dates = pd.date_range('2024-01-01', periods=20, freq='D').tolist() * 50
    
    # ç”Ÿæˆç‰¹å¾æ•°æ®
    feature_data = np.random.randn(n_samples, n_features)
    feature_columns = [f'feature_{i}' for i in range(n_features)]
    
    # ç”Ÿæˆç›®æ ‡æ•°æ®ï¼ˆæ¶¨è·Œå¹…ï¼‰
    target_data = np.random.normal(0, 0.02, n_samples)  # å¹³å‡0ï¼Œæ ‡å‡†å·®2%çš„æ¶¨è·Œå¹…
    
    # ç”Ÿæˆæ¬¡æ—¥æ¶¨è·Œå¹…
    next_day_return = np.random.normal(0, 0.025, n_samples)
    
    # åˆ›å»ºå®Œæ•´æ•°æ®æ¡†
    full_data = pd.DataFrame(feature_data, columns=feature_columns)
    full_data['stock_code'] = stock_codes[:n_samples]
    full_data['è‚¡ç¥¨åç§°'] = stock_names[:n_samples]
    full_data['date'] = dates[:n_samples]
    full_data['target'] = target_data
    full_data['æ¬¡æ—¥æ¶¨è·Œå¹…'] = next_day_return
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    full_data_path = test_data_dir / 'full_data.csv'
    full_data.to_csv(full_data_path, index=False, encoding='utf-8')
    
    print(f"âœ… æµ‹è¯•æ•°æ®å·²åˆ›å»º: {full_data_path}")
    print(f"   - æ ·æœ¬æ•°: {len(full_data):,}")
    print(f"   - ç‰¹å¾æ•°: {len(feature_columns)}")
    print(f"   - åŒ…å«åˆ—: {list(full_data.columns)}")
    
    return test_data_dir

def create_test_config(test_data_dir):
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    config = {
        "data": {
            "data_dir": str(test_data_dir),
            "X_features_file": "X_features.csv",
            "y_targets_file": "y_targets.csv", 
            "full_data_file": "full_data.csv",
            "loading_options": {
                "prefer_full_data": True,
                "encoding": "utf-8"
            },
            "direct_training": {
                "enabled": False
            },
            "preprocessing": {
                "normalization": {
                    "enabled": True,
                    "method": "robust"
                },
                "outlier_handling": {
                    "enabled": False
                }
            }
        },
        "training": {
            "data_split": {
                "test_size": 0.2,
                "validation_size": 0.1,
                "random_state": 42,
                "time_series_split": True
            },
            "model_params": {
                "objective": "regression",
                "metric": "rmse",
                "boosting_type": "gbdt",
                "num_leaves": 31,
                "learning_rate": 0.05,
                "feature_fraction": 0.9,
                "bagging_fraction": 0.8,
                "bagging_freq": 5,
                "verbose": -1,
                "random_state": 42
            },
            "fit_params": {
                "num_boost_round": 100,
                "valid_sets": ["train", "val"],
                "valid_names": ["train", "val"],
                "early_stopping_rounds": 20,
                "verbose_eval": False
            }
        },
        "output": {
            "model_save": {
                "save_dir": "./test_models",
                "save_format": ["pkl"]
            },
            "results_save": {
                "save_dir": "./test_results",
                "save_metrics": True,
                "save_predictions": True,
                "save_feature_importance": True
            }
        }
    }
    
    config_path = Path('./test_config.json')
    import json
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æµ‹è¯•é…ç½®å·²åˆ›å»º: {config_path}")
    return config_path

def test_predictions_enhancement():
    """æµ‹è¯•predictionså¢å¼ºåŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•predictionså¢å¼ºåŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®å’Œé…ç½®
    test_data_dir = create_test_data()
    config_path = create_test_config(test_data_dir)
    
    try:
        # å¯¼å…¥è®­ç»ƒå™¨
        from lightgbm_stock_train import LightGBMStockTrainer
        
        # åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
        trainer = LightGBMStockTrainer(str(config_path))
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“Š åŠ è½½æ•°æ®...")
        if not trainer.load_data():
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return False
        
        # åˆ†å‰²æ•°æ®
        print("\nâœ‚ï¸ åˆ†å‰²æ•°æ®...")
        if not trainer.split_data():
            print("âŒ æ•°æ®åˆ†å‰²å¤±è´¥")
            return False
        
        # æ£€æŸ¥è‚¡ç¥¨ä¿¡æ¯æ˜¯å¦æ­£ç¡®ä¿å­˜
        if hasattr(trainer, 'stock_info_train') and trainer.stock_info_train is not None:
            print("âœ… è‚¡ç¥¨ä¿¡æ¯ä¿å­˜æˆåŠŸ")
            print(f"   - è®­ç»ƒé›†è‚¡ç¥¨ä¿¡æ¯: {trainer.stock_info_train.shape}")
            print(f"   - éªŒè¯é›†è‚¡ç¥¨ä¿¡æ¯: {trainer.stock_info_val.shape}")
            print(f"   - æµ‹è¯•é›†è‚¡ç¥¨ä¿¡æ¯: {trainer.stock_info_test.shape}")
            print(f"   - è‚¡ç¥¨ä¿¡æ¯åˆ—: {list(trainer.stock_info_train.columns)}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ä¿¡æ¯")
        
        # é¢„å¤„ç†ç‰¹å¾
        print("\nğŸ”§ é¢„å¤„ç†ç‰¹å¾...")
        if not trainer.preprocess_features():
            print("âŒ ç‰¹å¾é¢„å¤„ç†å¤±è´¥")
            return False
        
        # è®­ç»ƒæ¨¡å‹
        print("\nğŸ¯ è®­ç»ƒæ¨¡å‹...")
        if not trainer.train_model():
            print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return False
        
        # è¯„ä¼°æ¨¡å‹
        print("\nğŸ“Š è¯„ä¼°æ¨¡å‹...")
        results = trainer.evaluate_model()
        if not results:
            print("âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥")
            return False
        
        # ä¿å­˜ç»“æœï¼ˆåŒ…æ‹¬å¢å¼ºçš„predictions.csvï¼‰
        print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
        if not trainer.save_results(results):
            print("âŒ ç»“æœä¿å­˜å¤±è´¥")
            return False
        
        # æ£€æŸ¥predictions.csvæ–‡ä»¶
        predictions_path = trainer.results_save_dir / "predictions.csv"
        if predictions_path.exists():
            pred_df = pd.read_csv(predictions_path)
            print(f"\nâœ… predictions.csvç”ŸæˆæˆåŠŸ: {predictions_path}")
            print(f"   - è®°å½•æ•°: {len(pred_df):,}")
            print(f"   - åˆ—æ•°: {len(pred_df.columns)}")
            print(f"   - åˆ—å: {list(pred_df.columns)}")
            
            # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
            print(f"\nğŸ“‹ å‰5è¡Œæ•°æ®é¢„è§ˆ:")
            print(pred_df.head())
            
            return True
        else:
            print("âŒ predictions.csvæ–‡ä»¶æœªç”Ÿæˆ")
            return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        import shutil
        try:
            if test_data_dir.exists():
                shutil.rmtree(test_data_dir)
            if config_path.exists():
                config_path.unlink()
            
            # æ¸…ç†ç”Ÿæˆçš„ç»“æœç›®å½•
            test_models_dir = Path('./test_models')
            test_results_dir = Path('./test_results')
            if test_models_dir.exists():
                shutil.rmtree(test_models_dir)
            if test_results_dir.exists():
                shutil.rmtree(test_results_dir)
            
            print("âœ… æµ‹è¯•æ–‡ä»¶æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ–‡ä»¶æ—¶å‡ºç°é—®é¢˜: {e}")

if __name__ == "__main__":
    success = test_predictions_enhancement()
    if success:
        print("\nğŸ‰ predictionså¢å¼ºåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("ç°åœ¨predictions.csvæ–‡ä»¶å°†åŒ…å«è‚¡ç¥¨ä»£ç ã€åç§°ã€æ—¥æœŸå’Œæ¬¡æ—¥æ¶¨è·Œå¹…ç­‰ä¿¡æ¯ã€‚")
    else:
        print("\nğŸ’¡ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¿®æ”¹çš„ä»£ç ã€‚")