# LightGBM 精细调优配置文件
# 基于性能对比结果的针对性优化版本
#
# 调优策略：
# 1. 保留原始配置中表现好的部分（异常值移除、standard标准化）
# 2. 优化特征选择策略（更保守的阈值，保留更多有用特征）
# 3. 增强模型参数（更强的正则化，防止过拟合）
# 4. 改进超参数搜索范围

# ===========================================
# 数据配置
# ===========================================
data:
  data_dir: "./data/datas_processed/processed_20250810_015407"
  
  X_features_file: "X_features.csv"
  y_targets_file: "y_targets.csv"
  full_data_file: "full_data.csv"
  stock_codes_file: "stock_codes.json"
  data_info_file: "data_info.json"
  
  loading_options:
    prefer_full_data: true
    encoding: "utf-8"
    validate_data: true
    
  timeseries_window:
    validate_completeness: true
    min_samples_per_stock: 8
    show_window_analysis: true
  
  # 精细调优的数据预处理
  preprocessing:
    # 改回flatten以保留时序信息
    timeseries_method: "flatten"
    
    feature_engineering:
      # 适度的统计特征（不要过多）
      statistical_features:
        - "mean"
        - "std"
        - "max"
        - "min"
        - "median"
        - "skew"
        
      # 技术指标保持启用但简化
      technical_features:
        enabled: true
        features:
          - "momentum"
          - "volatility"
          - "trend"
    
    # 回到standard标准化（原始配置表现更好）
    normalization:
      method: "standard"
      
    # 改回原始的异常值处理方式（移除策略）
    outlier_handling:
      enabled: true
      method: "iqr"  # 回到原始的IQR方法
      threshold: 2.5  # 稍微严格一点

# ===========================================
# 训练配置
# ===========================================
training:
  data_split:
    test_size: 0.2     # 保持原始比例
    validation_size: 0.1
    random_state: 42
    stratify: false
    
  cross_validation:
    enabled: true
    cv_folds: 5
    cv_strategy: "time_series"
    
  training_params:
    early_stopping_rounds: 100  # 回到原始设置
    verbose: 100
    eval_metric: ["rmse", "mae"]

# ===========================================
# LightGBM 参数 - 精细调优
# ===========================================
lightgbm:
  # 基础参数 - 在原始基础上微调
  basic_params:
    objective: "regression"
    metric: "rmse"
    boosting_type: "gbdt"
    num_leaves: 63        # 适中的复杂度
    learning_rate: 0.08   # 稍微降低学习率
    feature_fraction: 0.85 # 适中的特征采样
    bagging_fraction: 0.8  # 保持原始设置
    bagging_freq: 5
    verbose: -1
    random_state: 42
    
  # 进阶参数 - 增强正则化
  advanced_params:
    max_depth: 6           # 限制深度防止过拟合
    min_data_in_leaf: 50   # 增加最小叶子样本数
    min_gain_to_split: 0.05
    lambda_l1: 0.5         # 适度的L1正则化
    lambda_l2: 0.5         # 适度的L2正则化
    min_data_in_bin: 3
    bin_construct_sample_cnt: 200000
    
  fit_params:
    num_boost_round: 1000
    categorical_feature: "auto"

# ===========================================
# 特征选择 - 保守策略
# ===========================================
feature_selection:
  enabled: true
  methods:
    # 基于重要性的选择 - 更保守的阈值
    importance_based:
      enabled: true
      threshold: 0.005     # 提高到0.005（原来0.001太激进）
      method: "gain"
      
    # 基于相关性的选择 - 更宽松的阈值
    correlation_based:
      enabled: true
      threshold: 0.95      # 只移除极高相关的特征
      
    # 禁用RFE，避免过度减少特征
    rfe:
      enabled: false

# ===========================================
# 超参数优化 - 针对性调整
# ===========================================
hyperparameter_tuning:
  enabled: true
  method: "optuna"
  
  optuna_config:
    n_trials: 30
    timeout: 2400  # 40分钟
    
    # 基于当前最佳配置的微调范围
    param_ranges:
      num_leaves: [31, 127]          # 围绕当前最佳值调整
      learning_rate: [0.05, 0.15]    # 保守的学习率范围
      feature_fraction: [0.7, 0.9]   # 适中的特征采样
      bagging_fraction: [0.7, 0.9]   # 适中的样本采样
      min_data_in_leaf: [30, 100]    # 合理的叶子大小
      lambda_l1: [0.0, 2.0]          # 适度的正则化
      lambda_l2: [0.0, 2.0]

# ===========================================
# 输出配置
# ===========================================
output:
  file_naming:
    identifier_type: "unique_id"
    unique_id_digits: 3
    folder_name_prefix: "training_fine_tuned"
    show_id_in_log: true
  
  model_save:
    save_dir: "./models/lightgbm_fine_tuned"
    model_name: "lightgbm_stock_model_fine_tuned"
    save_format: ["pkl", "txt"]
    
  results_save:
    save_dir: "./results/lightgbm_fine_tuned"
    save_predictions: true
    save_feature_importance: true
    save_metrics: true
    save_plots: true
    
  logging:
    log_level: "INFO"
    log_file: "./logs/lightgbm_training_fine_tuned.log"
    console_output: true

# ===========================================
# 评估配置
# ===========================================
evaluation:
  metrics:
    - "rmse"
    - "mae"
    - "mape"
    - "r2_score"
    - "explained_variance"
    
  visualization:
    enabled: true
    plots:
      - "feature_importance"
      - "prediction_vs_actual"
      - "residuals"
      - "learning_curve"

# ===========================================
# 其他配置
# ===========================================
misc:
  n_jobs: -1
  
  memory_optimization:
    enabled: true
    chunk_size: 10000
    
  random_seed: 42
  
  gpu_config:
    enabled: false
    device_type: "cuda"

# ===========================================
# 新增：渐进式特征选择
# ===========================================
progressive_feature_selection:
  enabled: true
  # 分阶段特征选择，避免一次性删除过多特征
  stages:
    - name: "remove_low_variance"
      method: "variance_threshold"
      threshold: 0.01
    - name: "remove_highly_correlated"
      method: "correlation"
      threshold: 0.95
    - name: "select_important_features"
      method: "importance"
      threshold: 0.005
      
# ===========================================
# 新增：模型验证策略
# ===========================================
validation_strategy:
  # 使用时序分割验证
  time_series_validation: true
  # 保留最近数据作为时序验证集
  holdout_recent_ratio: 0.1
  # 滚动窗口验证
  rolling_window_validation: false