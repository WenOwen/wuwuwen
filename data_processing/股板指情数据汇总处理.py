#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®é¢„å¤„ç†æ¨¡å—
"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import glob
import warnings
from datetime import datetime
import pickle
import json

warnings.filterwarnings('ignore')


class ImprovedDataProcessor:
    """æ”¹è¿›çš„æ•°æ®å¤„ç†å™¨ï¼šæ¯åªè‚¡ç¥¨åªä½¿ç”¨æ‰€å±è¡Œä¸šç‰¹å¾"""
    
    def __init__(self, data_base_path: str = "./data"):
        self.data_base_path = data_base_path
        self.stock_path = os.path.join(data_base_path, "datas_em")
        self.industry_path = os.path.join(data_base_path, "datas_sector_historical/è¡Œä¸šæ¿å—_å…¨éƒ¨å†å²")
        self.index_path = os.path.join(data_base_path, "datas_index/datas_index")
        self.concept_path = os.path.join(data_base_path, "datas_sector_historical/æ¦‚å¿µæ¿å—_å…¨éƒ¨å†å²")
        
        # è‚¡ç¥¨è¡Œä¸šæ˜ å°„ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µæ„å»ºï¼‰
        self.stock_sector_mapping = self._create_stock_sector_mapping()
        
        # è¡Œä¸šä»£ç åˆ°æ–‡ä»¶åçš„æ˜ å°„
        self.sector_file_mapping = self._create_sector_file_mapping()
        
    def _create_stock_sector_mapping(self) -> Dict[str, str]:
        """
        ä»çœŸå®çš„è‚¡ç¥¨æ¿å—æ˜ å°„è¡¨åˆ›å»ºè‚¡ç¥¨åˆ°è¡Œä¸šçš„æ˜ å°„å…³ç³»
        """
        mapping = {}
        
        # è¯»å–çœŸå®çš„è‚¡ç¥¨æ¿å—æ˜ å°„è¡¨
        mapping_file = os.path.join(self.data_base_path, "datas_sector_historical/è‚¡ç¥¨æ¿å—æ˜ å°„è¡¨.csv")
        
        if not os.path.exists(mapping_file):
            print(f"è­¦å‘Šï¼šæ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨ {mapping_file}ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„")
            return self._create_default_mapping()
        
        try:
            df = pd.read_csv(mapping_file, encoding='utf-8')
            
            for _, row in df.iterrows():
                stock_code = str(row['è‚¡ç¥¨ä»£ç ']).lower()  # è½¬ä¸ºå°å†™
                sector = row['æ‰€å±è¡Œä¸š']
                
                # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼ï¼Œå»æ‰å¯èƒ½çš„å‰ç¼€
                if stock_code.startswith('sh') or stock_code.startswith('sz'):
                    clean_code = stock_code[2:]  # å»æ‰sh/szå‰ç¼€
                else:
                    clean_code = stock_code
                
                # åŒæ—¶ä¿å­˜åŸå§‹æ ¼å¼å’Œæ¸…ç†åçš„æ ¼å¼
                mapping[stock_code] = sector
                mapping[clean_code] = sector
                
                # ä¹Ÿä¿å­˜æˆ‘ä»¬æ•°æ®æ–‡ä»¶ä¸­çš„æ ¼å¼ (å¦‚sz301559)
                if len(clean_code) == 6:
                    if clean_code.startswith('0') or clean_code.startswith('3'):
                        file_format = f"sz{clean_code}"
                    else:
                        file_format = f"sh{clean_code}"
                    mapping[file_format] = sector
            
            print(f"ä»æ˜ å°„è¡¨åŠ è½½äº† {len(df)} ä¸ªè‚¡ç¥¨çš„è¡Œä¸šæ˜ å°„")
            print(f"æ˜ å°„å­—å…¸åŒ…å« {len(mapping)} ä¸ªæ¡ç›®")
            
            # æ˜¾ç¤ºä¸€äº›è¡Œä¸šç»Ÿè®¡
            sector_counts = {}
            for sector in mapping.values():
                sector_counts[sector] = sector_counts.get(sector, 0) + 1
            
            print("ä¸»è¦è¡Œä¸šåˆ†å¸ƒ:")
            for sector, count in sorted(sector_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
                print(f"  {sector}: {count} åªè‚¡ç¥¨")
                
        except Exception as e:
            print(f"è¯»å–æ˜ å°„æ–‡ä»¶å‡ºé”™: {e}")
            return self._create_default_mapping()
            
        return mapping
    
    def _create_default_mapping(self) -> Dict[str, str]:
        """åˆ›å»ºé»˜è®¤çš„è‚¡ç¥¨åˆ°è¡Œä¸šæ˜ å°„ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        mapping = {}
        stock_files = glob.glob(os.path.join(self.stock_path, "*.csv"))
        
        # é»˜è®¤è¡Œä¸šåˆ†é…
        default_sectors = ['é“¶è¡Œ', 'åŒ»è¯å•†ä¸š', 'è½¯ä»¶å¼€å‘', 'ä¸“ç”¨è®¾å¤‡', 'é£Ÿå“é¥®æ–™', 
                          'æˆ¿åœ°äº§å¼€å‘', 'çŸ³æ²¹è¡Œä¸š', 'åŒ–å­¦åˆ¶å“', 'èˆªè¿æ¸¯å£']
        
        for i, stock_file in enumerate(stock_files):
            stock_code = os.path.basename(stock_file).replace('.csv', '')
            sector = default_sectors[i % len(default_sectors)]
            mapping[stock_code] = sector
            
        print(f"ä½¿ç”¨é»˜è®¤æ˜ å°„åˆ›å»ºäº† {len(mapping)} ä¸ªè‚¡ç¥¨çš„è¡Œä¸šæ˜ å°„")
        return mapping
    
    def _create_sector_file_mapping(self) -> Dict[str, str]:
        """åˆ›å»ºè¡Œä¸šåç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„"""
        mapping = {}
        industry_files = glob.glob(os.path.join(self.industry_path, "*.csv"))
        
        for file_path in industry_files:
            filename = os.path.basename(file_path)
            sector_name = filename.split('(')[0]  # æå–è¡Œä¸šåç§°
            mapping[sector_name] = file_path
            
        print(f"æ‰¾åˆ° {len(mapping)} ä¸ªè¡Œä¸šæ¿å—æ–‡ä»¶")
        return mapping
    
    def load_individual_stock_data(self, limit_stocks: Optional[int] = None) -> Dict[str, pd.DataFrame]:
        """
        åŠ è½½ä¸ªè‚¡æ•°æ®ï¼Œä¿æŒæ¯åªè‚¡ç¥¨ç‹¬ç«‹
        """
        print("æ­£åœ¨åŠ è½½ä¸ªè‚¡æ•°æ®...")
        
        stock_files = glob.glob(os.path.join(self.stock_path, "*.csv"))
        if limit_stocks:
            stock_files = stock_files[:limit_stocks]
            
        print(f"æ‰¾åˆ° {len(stock_files)} ä¸ªè‚¡ç¥¨æ–‡ä»¶")
        
        stock_data_dict = {}
        
        for i, file_path in enumerate(stock_files):
            if i % 100 == 0:
                progress = (i+1) / len(stock_files) * 100
                print(f"å¤„ç†è¿›åº¦: {i+1}/{len(stock_files)} ({progress:.1f}%)")
                
            try:
                stock_code = os.path.basename(file_path).replace('.csv', '')
                df = pd.read_csv(file_path, encoding='utf-8')
                
                # æ ‡å‡†åŒ–åˆ—åå’Œç´¢å¼•
                df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'])
                df = df.drop_duplicates(subset=['äº¤æ˜“æ—¥æœŸ']).sort_values('äº¤æ˜“æ—¥æœŸ')
                df = df.set_index('äº¤æ˜“æ—¥æœŸ')
                
                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                df = self._calculate_technical_indicators(df)
                
                # é€‰æ‹©ä¸ªè‚¡ç‰¹å¾ï¼ˆ15ç»´ï¼‰
                feature_cols = [
                    'å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é‡', 
                    'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'RSI', 'MACD', 'MACD_signal', 
                    'BB_upper', 'BB_middle', 'BB_lower', 'ATR', 'ROC'
                ]
                
                # åªä¿ç•™å­˜åœ¨çš„åˆ—
                available_cols = [col for col in feature_cols if col in df.columns]
                df_selected = df[available_cols].copy()
                
                # ç¡®ä¿15ç»´ï¼Œä¸è¶³çš„ç”¨0å¡«å……
                while len(df_selected.columns) < 15:
                    df_selected[f'feature_{len(df_selected.columns)}'] = 0
                
                # è¶…è¿‡15ç»´åˆ™æˆªå–å‰15ç»´
                if len(df_selected.columns) > 15:
                    df_selected = df_selected.iloc[:, :15]
                
                stock_data_dict[stock_code] = df_selected
                
            except Exception as e:
                print(f"å¤„ç†è‚¡ç¥¨æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"æˆåŠŸåŠ è½½ {len(stock_data_dict)} åªè‚¡ç¥¨çš„æ•°æ®")
        return stock_data_dict
    
    def _calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰"""
        try:
            # RSI
            df['RSI'] = self._calculate_rsi(df['æ”¶ç›˜ä»·'])
            
            # MACD
            macd_data = self._calculate_macd(df['æ”¶ç›˜ä»·'])
            df['MACD'] = macd_data['MACD']
            df['MACD_signal'] = macd_data['MACD_signal']
            
            # å¸ƒæ—å¸¦
            bb_data = self._calculate_bollinger_bands(df['æ”¶ç›˜ä»·'])
            df['BB_upper'] = bb_data['upper']
            df['BB_middle'] = bb_data['middle']
            df['BB_lower'] = bb_data['lower']
            
            # ATR
            df['ATR'] = self._calculate_atr(df['æœ€é«˜ä»·'], df['æœ€ä½ä»·'], df['æ”¶ç›˜ä»·'])
            
            # ROC
            df['ROC'] = df['æ”¶ç›˜ä»·'].pct_change(periods=12) * 100
            
        except Exception as e:
            print(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            
        return df
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSI"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        avg_gain = gain.rolling(window=period).mean()
        avg_loss = loss.rolling(window=period).mean()
        
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Dict:
        """è®¡ç®—MACD"""
        exp1 = prices.ewm(span=fast).mean()
        exp2 = prices.ewm(span=slow).mean()
        macd = exp1 - exp2
        macd_signal = macd.ewm(span=signal).mean()
        
        return {
            'MACD': macd,
            'MACD_signal': macd_signal
        }
    
    def _calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: int = 2) -> Dict:
        """è®¡ç®—å¸ƒæ—å¸¦"""
        middle = prices.rolling(window=period).mean()
        std = prices.rolling(window=period).std()
        upper = middle + (std * std_dev)
        lower = middle - (std * std_dev)
        
        return {
            'upper': upper,
            'middle': middle,
            'lower': lower
        }
    
    def _calculate_atr(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—ATR"""
        prev_close = close.shift(1)
        tr1 = high - low
        tr2 = abs(high - prev_close)
        tr3 = abs(low - prev_close)
        
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(window=period).mean()
        return atr
    
    def load_sector_data(self) -> Dict[str, pd.DataFrame]:
        """åŠ è½½è¡Œä¸šæ¿å—æ•°æ®ï¼Œä¿æŒæ¯ä¸ªè¡Œä¸šç‹¬ç«‹"""
        print("æ­£åœ¨åŠ è½½è¡Œä¸šæ¿å—æ•°æ®...")
        
        sector_data_dict = {}
        
        for sector_name, file_path in self.sector_file_mapping.items():
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                
                # å»é‡å¹¶æ’åº
                df = df.drop_duplicates(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ')
                df = df.set_index('æ—¥æœŸ')
                
                # é€‰æ‹©è¡Œä¸šç‰¹å¾ï¼ˆ5ç»´ï¼šOHLCVï¼‰
                feature_cols = ['å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é‡']
                available_cols = [col for col in feature_cols if col in df.columns]
                
                if len(available_cols) >= 4:  # è‡³å°‘è¦æœ‰OHLC
                    df_selected = df[available_cols].copy()
                    
                    # ç¡®ä¿5ç»´
                    while len(df_selected.columns) < 5:
                        df_selected[f'sector_feature_{len(df_selected.columns)}'] = 0
                    
                    if len(df_selected.columns) > 5:
                        df_selected = df_selected.iloc[:, :5]
                    
                    sector_data_dict[sector_name] = df_selected
                    
            except Exception as e:
                print(f"å¤„ç†è¡Œä¸šæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"æˆåŠŸåŠ è½½ {len(sector_data_dict)} ä¸ªè¡Œä¸šæ¿å—æ•°æ®")
        return sector_data_dict
    
    def load_index_data(self) -> pd.DataFrame:
        """åŠ è½½æŒ‡æ•°æ•°æ®ï¼ˆ5ç»´ï¼‰"""
        print("æ­£åœ¨åŠ è½½æŒ‡æ•°æ•°æ®...")
        
        # ä¸»è¦æŒ‡æ•°æ˜ å°„
        index_mapping = {
            'zs000001.csv': 'ä¸Šè¯æŒ‡æ•°',
            'zs000300.csv': 'æ²ªæ·±300',
            'zs399001.csv': 'æ·±è¯æˆæŒ‡',
            'zs399006.csv': 'åˆ›ä¸šæ¿æŒ‡',
            'zs000905.csv': 'ä¸­è¯500'
        }
        
        all_index_data = []
        
        for filename, index_name in index_mapping.items():
            file_path = os.path.join(self.index_path, filename)
            
            if not os.path.exists(file_path):
                continue
                
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'])
                
                # å»é‡å¹¶æ’åº
                df = df.drop_duplicates(subset=['äº¤æ˜“æ—¥æœŸ']).sort_values('äº¤æ˜“æ—¥æœŸ')
                df = df.set_index('äº¤æ˜“æ—¥æœŸ')
                
                # åªå–ä¸€ä¸ªä¸»è¦ç‰¹å¾ï¼ˆæ”¶ç›˜ä»·ï¼‰
                df_selected = df[['æ”¶ç›˜ä»·']].copy()
                df_selected.columns = [f"{index_name}"]
                
                all_index_data.append(df_selected)
                
            except Exception as e:
                print(f"å¤„ç†æŒ‡æ•°æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                continue
        
        if all_index_data:
            # åˆå¹¶æ‰€æœ‰æŒ‡æ•°æ•°æ®
            combined_data = all_index_data[0]
            for df in all_index_data[1:]:
                combined_data = combined_data.join(df, how='outer')
            
            # ç¡®ä¿5ç»´
            while len(combined_data.columns) < 5:
                combined_data[f'index_feature_{len(combined_data.columns)}'] = 0
            
            if len(combined_data.columns) > 5:
                combined_data = combined_data.iloc[:, :5]
                
            combined_data = combined_data.sort_index()
        else:
            # åˆ›å»ºç©ºæ•°æ®
            combined_data = pd.DataFrame()
        
        print(f"æŒ‡æ•°æ•°æ®å½¢çŠ¶: {combined_data.shape}")
        return combined_data
    
    def load_sentiment_data(self) -> pd.DataFrame:
        """
        åŠ è½½æƒ…ç»ªæ•°æ®ï¼šæ˜¨æ—¥è¿æ¿å’Œæ¶¨åœæ¿å—ï¼ˆ2ç»´ï¼‰
        """
        print("æ­£åœ¨åŠ è½½æƒ…ç»ªæ•°æ®...")
        
        # å¯»æ‰¾è¿æ¿å’Œæ¶¨åœç›¸å…³æ¿å—
        concept_files = glob.glob(os.path.join(self.concept_path, "*.csv"))
        
        limit_up_files = []
        consecutive_files = []
        
        for file_path in concept_files:
            filename = os.path.basename(file_path)
            if 'æ¶¨åœ' in filename:
                limit_up_files.append(file_path)
            if 'è¿æ¿' in filename or 'è¿ç»­' in filename:
                consecutive_files.append(file_path)
        
    
        # å¤„ç†æ¶¨åœæ•°æ®
        limit_up_data = self._process_sentiment_concept_data(limit_up_files[:1], "æ¶¨åœå¼ºåº¦")
        
        # å¤„ç†è¿æ¿æ•°æ®
        consecutive_data = self._process_sentiment_concept_data(consecutive_files[:1], "è¿æ¿å¼ºåº¦")
        
        # åˆå¹¶ä¸º2ç»´æƒ…ç»ªæ•°æ®
        if not limit_up_data.empty and not consecutive_data.empty:
            sentiment_data = pd.concat([limit_up_data, consecutive_data], axis=1)
        elif not limit_up_data.empty:
            sentiment_data = limit_up_data
            sentiment_data['è¿æ¿å¼ºåº¦'] = 0  # æ·»åŠ ç¬¬äºŒç»´
        elif not consecutive_data.empty:
            sentiment_data = consecutive_data
            sentiment_data['æ¶¨åœå¼ºåº¦'] = 0  # æ·»åŠ ç¬¬ä¸€ç»´
        else:
            # åˆ›å»ºç©ºæ•°æ®
            dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')
            sentiment_data = pd.DataFrame({
                'æ¶¨åœå¼ºåº¦': np.zeros(len(dates)),
                'è¿æ¿å¼ºåº¦': np.zeros(len(dates))
            }, index=dates)
        
        # ç¡®ä¿2ç»´
        while len(sentiment_data.columns) < 2:
            sentiment_data[f'sentiment_feature_{len(sentiment_data.columns)}'] = 0
        
        if len(sentiment_data.columns) > 2:
            sentiment_data = sentiment_data.iloc[:, :2]
        
        print(f"æƒ…ç»ªæ•°æ®å½¢çŠ¶: {sentiment_data.shape}")
        return sentiment_data
    
    def _process_sentiment_concept_data(self, file_list: List[str], feature_name: str) -> pd.DataFrame:
        """å¤„ç†æƒ…ç»ªæ¦‚å¿µæ•°æ®"""
        if not file_list:
            return pd.DataFrame()
        
        all_data = []
        
        for file_path in file_list:
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                
                # å»é‡å¹¶æ’åº
                df = df.drop_duplicates(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ')
                df = df.set_index('æ—¥æœŸ')
                
                # ä½¿ç”¨æ¶¨è·Œå¹…ä½œä¸ºå¼ºåº¦æŒ‡æ ‡
                if 'æ¶¨è·Œå¹…' in df.columns:
                    df_selected = df[['æ¶¨è·Œå¹…']].copy()
                    df_selected.columns = [feature_name]
                    all_data.append(df_selected)
                
            except Exception as e:
                print(f"å¤„ç†æƒ…ç»ªæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        if all_data:
            # å–å¹³å‡å€¼
            combined_data = pd.concat(all_data, axis=1)
            result = combined_data.mean(axis=1).to_frame(feature_name)
            return result
        
        return pd.DataFrame()
    
    def create_training_samples(self, stock_data_dict: Dict[str, pd.DataFrame],
                              sector_data_dict: Dict[str, pd.DataFrame],
                              index_data: pd.DataFrame,
                              sentiment_data: pd.DataFrame,
                              window_size: int = 30) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """
        åˆ›å»ºè®­ç»ƒæ ·æœ¬ï¼šæ¯åªè‚¡ç¥¨ä½¿ç”¨å…¶æ‰€å±è¡Œä¸šçš„ç‰¹å¾
        """
        print("æ­£åœ¨åˆ›å»ºè®­ç»ƒæ ·æœ¬...")
        
        all_samples = []
        all_targets = []
        all_stock_codes = []
        
        for stock_code, stock_df in stock_data_dict.items():
            try:
                # è·å–è¯¥è‚¡ç¥¨æ‰€å±çš„è¡Œä¸š
                sector_name = self.stock_sector_mapping.get(stock_code, 'é“¶è¡Œ')  # é»˜è®¤é“¶è¡Œ
                
                # å¯»æ‰¾åŒ¹é…çš„è¡Œä¸šæ•°æ®
                sector_df = None
                for sector_key, sector_data in sector_data_dict.items():
                    if sector_name in sector_key:
                        sector_df = sector_data
                        break
                
                if sector_df is None:
                    # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„è¡Œä¸šï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„è¡Œä¸šæ•°æ®
                    if sector_data_dict:
                        sector_df = list(sector_data_dict.values())[0]
                    else:
                        # åˆ›å»ºç©ºçš„è¡Œä¸šæ•°æ®
                        sector_df = pd.DataFrame(
                            np.zeros((len(stock_df), 5)),
                            index=stock_df.index,
                            columns=[f'sector_feature_{i}' for i in range(5)]
                        )
                
                # æ•°æ®å¯¹é½
                common_dates = stock_df.index.intersection(sector_df.index)
                common_dates = common_dates.intersection(index_data.index)
                common_dates = common_dates.intersection(sentiment_data.index)
                
                if len(common_dates) < window_size + 1:
                    continue
                
                # é‡æ–°ç´¢å¼•
                stock_aligned = stock_df.reindex(common_dates).fillna(method='ffill').fillna(0)
                sector_aligned = sector_df.reindex(common_dates).fillna(method='ffill').fillna(0)
                index_aligned = index_data.reindex(common_dates).fillna(method='ffill').fillna(0)
                sentiment_aligned = sentiment_data.reindex(common_dates).fillna(method='ffill').fillna(0)
                
                # åˆ›å»ºæ»‘åŠ¨çª—å£æ ·æœ¬
                for i in range(len(common_dates) - window_size):
                    # ç‰¹å¾çª—å£
                    window_start = i
                    window_end = i + window_size
                    
                    # æ‹¼æ¥ç‰¹å¾ï¼šä¸ªè‚¡(15) + è¡Œä¸š(5) + æŒ‡æ•°(5) + æƒ…ç»ª(2) = 27ç»´
                    stock_window = stock_aligned.iloc[window_start:window_end].values  # (30, 15)
                    sector_window = sector_aligned.iloc[window_start:window_end].values  # (30, 5)
                    index_window = index_aligned.iloc[window_start:window_end].values  # (30, 5)
                    sentiment_window = sentiment_aligned.iloc[window_start:window_end].values  # (30, 2)
                    
                    # åˆå¹¶ç‰¹å¾
                    combined_window = np.hstack([
                        stock_window, sector_window, index_window, sentiment_window
                    ])  # (30, 27)
                    
                    # ç›®æ ‡ï¼šä¸‹ä¸€å¤©çš„è‚¡ç¥¨æ”¶ç›Šç‡
                    target_idx = window_end
                    if target_idx < len(stock_aligned) and 'æ¶¨è·Œå¹…' in stock_aligned.columns:
                        target = stock_aligned.iloc[target_idx]['æ¶¨è·Œå¹…']
                    else:
                        # è®¡ç®—æ”¶ç›Šç‡
                        if target_idx < len(stock_aligned) and 'æ”¶ç›˜ä»·' in stock_aligned.columns:
                            current_price = stock_aligned.iloc[window_end - 1]['æ”¶ç›˜ä»·']
                            next_price = stock_aligned.iloc[target_idx]['æ”¶ç›˜ä»·']
                            target = (next_price - current_price) / current_price * 100
                        else:
                            continue
                    
                    all_samples.append(combined_window)
                    all_targets.append(target)
                    all_stock_codes.append(stock_code)
                    
            except Exception as e:
                print(f"å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                continue
        
        if not all_samples:
            raise ValueError("æ²¡æœ‰ç”Ÿæˆä»»ä½•è®­ç»ƒæ ·æœ¬")
        
        X = np.array(all_samples)
        y = np.array(all_targets)
        
        print(f"ç”Ÿæˆè®­ç»ƒæ ·æœ¬: X={X.shape}, y={y.shape}")
        print(f"ç‰¹å¾ç»´åº¦: ä¸ªè‚¡(15) + è¡Œä¸š(5) + æŒ‡æ•°(5) + æƒ…ç»ª(2) = {X.shape[-1]}ç»´")
        print(f"æ ·æœ¬ç»Ÿè®¡: æ¶‰åŠ{len(set(all_stock_codes))}åªè‚¡ç¥¨")
        
        return X, y, all_stock_codes
    
    def save_processed_data(self, X: np.ndarray, y: np.ndarray, 
                           stock_codes: List[str], save_dir: str = "./data/processed_v2") -> None:
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        os.makedirs(save_dir, exist_ok=True)
        
        print("æ­£åœ¨ä¿å­˜å¤„ç†åçš„æ•°æ®...")
        
        # ä¿å­˜numpyæ•°ç»„
        np.save(os.path.join(save_dir, "X_features.npy"), X)
        np.save(os.path.join(save_dir, "y_targets.npy"), y)
        
        # ä¿å­˜è‚¡ç¥¨ä»£ç åˆ—è¡¨
        with open(os.path.join(save_dir, "stock_codes.json"), 'w', encoding='utf-8') as f:
            json.dump(stock_codes, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ•°æ®ä¿¡æ¯
        info = {
            'X_shape': X.shape,
            'y_shape': y.shape,
            'feature_dims': {
                'stock': 15,
                'sector': 5,
                'index': 5,
                'sentiment': 2,
                'total': X.shape[-1]
            },
            'num_samples': X.shape[0],
            'num_stocks': len(set(stock_codes)),
            'processing_time': datetime.now().isoformat()
        }
        
        with open(os.path.join(save_dir, "data_info.json"), 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {save_dir}")
        print("ä¿å­˜çš„æ–‡ä»¶:")
        print("  - X_features.npy: ç‰¹å¾æ•°æ®")
        print("  - y_targets.npy: ç›®æ ‡æ•°æ®")
        print("  - stock_codes.json: è‚¡ç¥¨ä»£ç åˆ—è¡¨")
        print("  - data_info.json: æ•°æ®ä¿¡æ¯")


def main(limit_stocks=None):
    """
    ä¸»å¤„ç†æµç¨‹
    
    Args:
        limit_stocks: é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨è‚¡ç¥¨
    """
    print("å¼€å§‹æ”¹è¿›çš„æ•°æ®å¤„ç†...")
    
    if limit_stocks is None:
        print("âš ï¸  æ³¨æ„ï¼šå°†å¤„ç†å…¨éƒ¨è‚¡ç¥¨æ•°æ®ï¼ˆçº¦5400+åªï¼‰ï¼Œé¢„è®¡éœ€è¦è¾ƒé•¿æ—¶é—´å’Œå¤§é‡å†…å­˜")
        print("ğŸ’¡ å»ºè®®ï¼šå¦‚æœå†…å­˜ä¸è¶³ï¼Œå¯ä»¥è®¾ç½®limit_stockså‚æ•°é™åˆ¶è‚¡ç¥¨æ•°é‡")
        print("ğŸ“Š é¢„è®¡å†…å­˜éœ€æ±‚ï¼š16GB+ RAMï¼Œå¤„ç†æ—¶é—´ï¼š30-60åˆ†é’Ÿ")
    else:
        print(f"ğŸ“Š é™åˆ¶å¤„ç†è‚¡ç¥¨æ•°é‡ï¼š{limit_stocks} åª")
    
    # åˆ›å»ºæ”¹è¿›çš„æ•°æ®å¤„ç†å™¨
    processor = ImprovedDataProcessor(data_base_path="./data")
    
    try:
        # 1. åŠ è½½ä¸ªè‚¡æ•°æ®
        print(f"\nğŸ”„ æ­¥éª¤1/6: åŠ è½½ä¸ªè‚¡æ•°æ®...")
        stock_data_dict = processor.load_individual_stock_data(limit_stocks=limit_stocks)
        
        # 2. åŠ è½½è¡Œä¸šæ¿å—æ•°æ®
        print(f"\nğŸ”„ æ­¥éª¤2/6: åŠ è½½è¡Œä¸šæ¿å—æ•°æ®...")
        sector_data_dict = processor.load_sector_data()
        
        # 3. åŠ è½½æŒ‡æ•°æ•°æ®
        print(f"\nğŸ”„ æ­¥éª¤3/6: åŠ è½½æŒ‡æ•°æ•°æ®...")
        index_data = processor.load_index_data()
        
        # 4. åŠ è½½æƒ…ç»ªæ•°æ®
        print(f"\nğŸ”„ æ­¥éª¤4/6: åŠ è½½æƒ…ç»ªæ•°æ®...")
        sentiment_data = processor.load_sentiment_data()
        
        # 5. åˆ›å»ºè®­ç»ƒæ ·æœ¬
        print(f"\nğŸ”„ æ­¥éª¤5/6: åˆ›å»ºè®­ç»ƒæ ·æœ¬...")
        print("â³ è¿™ä¸€æ­¥å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        X, y, stock_codes = processor.create_training_samples(
            stock_data_dict, sector_data_dict, index_data, sentiment_data
        )
        
        # 6. ä¿å­˜å¤„ç†åçš„æ•°æ®
        print(f"\nğŸ”„ æ­¥éª¤6/6: ä¿å­˜å¤„ç†åçš„æ•°æ®...")
        processor.save_processed_data(X, y, stock_codes)
        
        print("\næ”¹è¿›çš„æ•°æ®å¤„ç†å®Œæˆï¼")
        print(f"æœ€ç»ˆæ•°æ®å½¢çŠ¶:")
        print(f"  ç‰¹å¾æ•°æ®: {X.shape}")
        print(f"  ç›®æ ‡æ•°æ®: {y.shape}")
        print(f"  ç‰¹å¾ç»´åº¦: {X.shape[-1]} (ä¸ªè‚¡15 + è¡Œä¸š5 + æŒ‡æ•°5 + æƒ…ç»ª2)")
        print(f"  æ¶‰åŠè‚¡ç¥¨: {len(set(stock_codes))} åª")
        
        # æ•°æ®ç»Ÿè®¡
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(f"  ç›®æ ‡å‡å€¼: {np.mean(y):.4f}")
        print(f"  ç›®æ ‡æ ‡å‡†å·®: {np.std(y):.4f}")
        print(f"  ç›®æ ‡èŒƒå›´: [{np.min(y):.4f}, {np.max(y):.4f}]")
        
    except Exception as e:
        print(f"æ•°æ®å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import sys
    
    # å‘½ä»¤è¡Œå‚æ•°å¤„ç†
    if len(sys.argv) > 1:
        try:
            limit_stocks = int(sys.argv[1])
            print(f"ğŸ“‹ ä»å‘½ä»¤è¡Œå‚æ•°è®¾ç½®è‚¡ç¥¨é™åˆ¶: {limit_stocks}")
            main(limit_stocks=limit_stocks)
        except ValueError:
            print("âŒ é”™è¯¯ï¼šè‚¡ç¥¨æ•°é‡å‚æ•°å¿…é¡»æ˜¯æ•´æ•°")
            print("ğŸ’¡ ç”¨æ³•ï¼špython è‚¡æ¿æŒ‡æƒ…æ•°æ®æ±‡æ€»å¤„ç†.py [è‚¡ç¥¨æ•°é‡]")
            print("ğŸ“ ç¤ºä¾‹ï¼špython è‚¡æ¿æŒ‡æƒ…æ•°æ®æ±‡æ€»å¤„ç†.py 100  # å¤„ç†100åªè‚¡ç¥¨")
            print("ğŸ“ ç¤ºä¾‹ï¼špython è‚¡æ¿æŒ‡æƒ…æ•°æ®æ±‡æ€»å¤„ç†.py     # å¤„ç†å…¨éƒ¨è‚¡ç¥¨")
    else:
        # é»˜è®¤å¤„ç†å…¨éƒ¨è‚¡ç¥¨
        main(limit_stocks=None)