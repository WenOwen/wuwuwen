# 专业数据整合脚本 - 日期范围处理说明

## 新增功能

现在脚本支持灵活的日期范围处理，可以避免重复处理已存在的文件。

## 主要改进

1. **指定日期范围**: 可以设置具体的开始和结束日期
2. **自动跳过已存在文件**: 避免重复处理，节省时间
3. **多种处理模式**: 支持不同的使用场景
4. **智能日期检测**: 自动扫描可用的交易日期

## 使用方法

### 1. 继续处理历史数据（推荐）

如果你已经处理了最近100个交易日，现在想处理更早的数据：

```python
processor = ProfessionalDataProcessor(
    start_date='2015-01-01',    # 从2015年开始
    end_date='2023-12-31',      # 到2023年结束
    skip_existing=True          # 跳过已存在的文件
)
```

### 2. 处理特定年份

只处理某个特定年份的数据：

```python
processor = ProfessionalDataProcessor(
    start_date='2022-01-01',    # 2022年开始
    end_date='2022-12-31',      # 2022年结束
    skip_existing=True
)
```

### 3. 从某日期开始到最新

从指定日期开始处理到最新数据：

```python
processor = ProfessionalDataProcessor(
    start_date='2020-01-01',    # 从2020年开始
    skip_existing=True          # 会处理到最新日期
)
```

### 4. 处理最近N天（原有模式）

只处理最近的N个交易日：

```python
processor = ProfessionalDataProcessor(
    recent_days=50,             # 最近50个交易日
    skip_existing=True
)
```

## 参数说明

- `start_date`: 开始日期，格式为 'YYYY-MM-DD'
- `end_date`: 结束日期，格式为 'YYYY-MM-DD' 
- `recent_days`: 最近N个交易日（当不指定start_date和end_date时使用）
- `skip_existing`: 是否跳过已存在的文件（强烈推荐设为True）

## 注意事项

1. **日期格式**: 必须使用 'YYYY-MM-DD' 格式
2. **文件检查**: 脚本会自动检查 `data/professional_parquet/` 目录下已存在的文件
3. **增量处理**: 设置 `skip_existing=True` 可以实现增量处理
4. **交易日检测**: 脚本只会处理实际存在交易数据的日期

## 运行示例

```bash
# 直接运行脚本
python professional_data_integration.py

# 脚本会显示当前设置的日期范围
# 并自动跳过已存在的文件
```

## 输出信息

脚本运行时会显示：

- 📅 指定的日期范围
- 📊 可用的交易日数量  
- ⏭️ 跳过的已存在文件数量
- 🎯 实际需要处理的文件数量
- 📈 最终的处理范围

## 常见用法

**场景1**: 你已经处理了最近100天，想继续处理2020-2023年的数据
```python
processor = ProfessionalDataProcessor(
    start_date='2020-01-01', 
    end_date='2023-12-31',
    skip_existing=True
)
```

**场景2**: 想补充处理2019年的数据
```python
processor = ProfessionalDataProcessor(
    start_date='2019-01-01',
    end_date='2019-12-31', 
    skip_existing=True
)
```

**场景3**: 从2018年开始处理到最新（慎用，数据量大）
```python
processor = ProfessionalDataProcessor(
    start_date='2018-01-01',
    skip_existing=True
)
```