# -*- coding: utf-8 -*-
# @å¾®ä¿¡:samequant
# @ç½‘ç«™:æ¶¨åœå®¢é‡åŒ–zhangtingke.com
# @æ›´å¤šæºç ä¸‹è½½åœ°å€: https://zhangtingke.com/download
# @ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ¶ˆé™¤é‡å¤ä»£ç ï¼Œæé«˜å¯ç»´æŠ¤æ€§

import os
import pandas as pd
import requests
import time
import random
import datetime
import json
from typing import Dict, List, Optional, Union
from abc import ABC, abstractmethod

# å¯¼å…¥å¤„ç† - æ”¯æŒç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥
try:
    from ..get_opening_calendar_from_szse.get_opening_calendar_from_szse import Get_stock_opening_calendar
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶çš„å¯¼å…¥
    import sys
    import os
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.append(project_root)
    try:
        from get_opening_calendar_from_szse.get_opening_calendar_from_szse import Get_stock_opening_calendar
    except ImportError:
        # å¦‚æœä»ç„¶æ— æ³•å¯¼å…¥ï¼Œæä¾›ä¸€ä¸ªç®€å•çš„æ›¿ä»£å®ç°
        class Get_stock_opening_calendar:
            def __init__(self):
                pass
            def get_calendar(self):
                return []

pd.set_option('expand_frame_repr', False)
pd.set_option('display.max_rows', 6000)


class Config:
    """é…ç½®ç±»ï¼Œç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®ä¿¡æ¯"""
    
    # ç½‘ç»œè¯·æ±‚é…ç½®
    DEFAULT_TIMEOUT = 30
    DEFAULT_MAX_RETRIES = 10
    DEFAULT_SLEEP_TIME = 1
    
    # ç”¨æˆ·ä»£ç†
    USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    ]
    
    # API åŸºç¡€URL
    EASTMONEY_BASE_URLS = {
        'quote': 'http://push2.eastmoney.com/api/qt',
        'history': 'http://push2his.eastmoney.com/api/qt',
        'list': 'http://push2.eastmoney.com/api/qt/clist',
        'stock': 'http://push2.eastmoney.com/api/qt/stock'
    }
    
    # ä¸Šäº¤æ‰€å’Œæ·±äº¤æ‰€é…ç½®
    SSE_CONFIG = {
        'headers': {
            'X-Requested-With': 'XMLHttpRequest',
            'User-Agent': USER_AGENTS[0],
            'Referer': 'http://www.sse.com.cn/assortment/stock/list/share/'
        },
        'base_url': 'http://query.sse.com.cn'
    }
    
    SZSE_CONFIG = {
        'headers': {
            'user-agent': USER_AGENTS[0]
        },
        'base_url': 'http://www.szse.cn/api/report/ShowReport'
    }
    
    # å­—æ®µæ˜ å°„é…ç½®
    FIELD_MAPPINGS = {
        'stock_basic': {
            'f12': 'è‚¡ç¥¨ä»£ç ', 'f14': 'è‚¡ç¥¨åç§°', 'f2': 'æœ€æ–°ä»·', 'f3': 'æ¶¨è·Œå¹…',
            'f4': 'æ¶¨è·Œé¢', 'f5': 'æˆäº¤é‡', 'f6': 'æˆäº¤é¢', 'f7': 'æŒ¯å¹…',
            'f15': 'æœ€é«˜ä»·', 'f16': 'æœ€ä½ä»·', 'f17': 'å¼€ç›˜ä»·', 'f18': 'æ˜¨æ”¶ä»·',
            'f20': 'æ€»å¸‚å€¼', 'f21': 'æµé€šå¸‚å€¼', 'f8': 'æ¢æ‰‹ç‡', 'f9': 'å¸‚ç›ˆç‡',
            'f23': 'å¸‚å‡€ç‡', 'f11': 'æ¶¨é€Ÿ', 'f10': 'é‡æ¯”'
        },
        'money_flow': {
            'f62': 'ä¸»åŠ›å‡€æµå…¥', 'f184': 'ä¸»åŠ›å‡€æµå…¥å æ¯”',
            'f66': 'è¶…å¤§å•å‡€æµå…¥', 'f69': 'è¶…å¤§å•å‡€æµå…¥å æ¯”',
            'f72': 'å¤§å•å‡€æµå…¥', 'f75': 'å¤§å•å‡€æµå…¥å æ¯”',
            'f78': 'ä¸­å•å‡€æµå…¥', 'f81': 'å°å•å‡€æµå…¥'
        },
        'sector': {
            'f12': 'ä»£ç ', 'f14': 'åç§°', 'f2': 'æœ€æ–°ä»·', 'f3': 'æ¶¨è·Œå¹…',
            'f4': 'æ¶¨è·Œé¢', 'f5': 'æˆäº¤é‡', 'f6': 'æˆäº¤é¢', 'f7': 'æŒ¯å¹…',
            'f84': 'æ€»è‚¡æœ¬', 'f124': 'æ›´æ–°æ—¶é—´'
        }
    }


class BaseNetworkClient:
    """åŸºç¡€ç½‘ç»œå®¢æˆ·ç«¯ï¼Œç»Ÿä¸€å¤„ç†ç½‘ç»œè¯·æ±‚"""
    
    def __init__(self):
        self.session = requests.Session()
    
    def make_request(self, url: str, headers: Dict = None, params: Dict = None, 
                    max_retries: int = Config.DEFAULT_MAX_RETRIES, 
                    sleep_time: float = Config.DEFAULT_SLEEP_TIME,
                    timeout: int = Config.DEFAULT_TIMEOUT) -> requests.Response:
        """
        ç»Ÿä¸€çš„ç½‘ç»œè¯·æ±‚æ–¹æ³•
        """
        if headers is None:
            headers = {'User-Agent': random.choice(Config.USER_AGENTS)}
        
        for attempt in range(max_retries):
            try:
                response = self.session.get(
                    url=url, 
                    headers=headers, 
                    params=params,
                    timeout=timeout
                )
                response.raise_for_status()
                return response
                
            except Exception as e:
                print(f'è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}')
                if attempt < max_retries - 1:
                    time.sleep(sleep_time)
                else:
                    raise ValueError(f'ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}')
    
    def download_file(self, url: str, save_path: str, headers: Dict = None, 
                     params: Dict = None) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„
        """
        try:
            response = self.make_request(url, headers, params)
            
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=10000):
                    if chunk:
                        f.write(chunk)
            
            print(f'æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {save_path}')
            return True
            
        except Exception as e:
            print(f'æ–‡ä»¶ä¸‹è½½å¤±è´¥: {e}')
            return False


class BaseDataProcessor:
    """åŸºç¡€æ•°æ®å¤„ç†ç±»"""
    
    @staticmethod
    def symbol_to_stock_code(symbol: Union[str, int]) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–æ–¹æ³•
        """
        if len(str(symbol)) < 6:
            symbol = str(symbol).rjust(6, '0')
        elif len(str(symbol)) == 6:
            symbol = str(symbol)
        else:
            return str(symbol)
        
        if symbol.startswith('6'):
            return 'sh' + symbol
        elif symbol.startswith(('0', '3')):
            return 'sz' + symbol
        elif symbol.startswith(('4', '8', '9')):
            return 'bj' + symbol
        else:
            return symbol
    
    @staticmethod
    def rename_dataframe_columns(df: pd.DataFrame, field_mapping: Dict[str, str]) -> pd.DataFrame:
        """
        ç»Ÿä¸€çš„DataFrameåˆ—é‡å‘½åæ–¹æ³•
        """
        # åªé‡å‘½åå­˜åœ¨çš„åˆ—
        available_mappings = {k: v for k, v in field_mapping.items() if k in df.columns}
        return df.rename(columns=available_mappings)
    
    @staticmethod
    def convert_numeric_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:
        """
        ç»Ÿä¸€çš„æ•°å€¼åˆ—è½¬æ¢æ–¹æ³•
        """
        for col in columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        return df
    
    @staticmethod
    def clean_and_save_dataframe(df: pd.DataFrame, save_path: str, 
                                encoding: str = 'utf-8') -> bool:
        """
        ç»Ÿä¸€çš„DataFrameæ¸…ç†å’Œä¿å­˜æ–¹æ³•
        """
        try:
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            df.to_csv(save_path, index=False, encoding=encoding)
            print(f'æ•°æ®ä¿å­˜æˆåŠŸ: {save_path} (å…±{len(df)}æ¡è®°å½•)')
            return True
            
        except Exception as e:
            print(f'æ•°æ®ä¿å­˜å¤±è´¥: {e}')
            return False


class EastmoneyAPIClient(BaseNetworkClient):
    """ä¸œæ–¹è´¢å¯ŒAPIå®¢æˆ·ç«¯ï¼Œç»Ÿä¸€å¤„ç†ä¸œæ–¹è´¢å¯Œç›¸å…³çš„APIè°ƒç”¨"""
    
    def __init__(self):
        super().__init__()
        self.base_urls = Config.EASTMONEY_BASE_URLS
    
    def _get_secid(self, stock_code: str) -> str:
        """è·å–secidæ ¼å¼"""
        if len(stock_code) == 6:
            symbol = stock_code
        elif len(stock_code) == 8:
            symbol = stock_code[2:]
        else:
            return ""
        
        if symbol[0] == '6':
            return f"1.{symbol}"
        elif symbol[0] in ['0', '3']:
            return f"0.{symbol}"
        else:
            return f"0.{symbol}"
    
    def _get_timestamp(self) -> int:
        """è·å–13ä½æ—¶é—´æˆ³"""
        return int(time.time() * 1000)
    
    def get_stock_realtime_data(self, stock_codes: Union[str, List[str]], 
                               fields: str = None) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å®æ—¶æ•°æ®çš„ç»Ÿä¸€æ–¹æ³•
        """
        if isinstance(stock_codes, str):
            stock_codes = [stock_codes]
        
        if fields is None:
            fields = 'f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152'
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        fs_param = 'm:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048'
        
        all_data = []
        page_size = 200
        
        for page in range(1, 50):  # æœ€å¤š50é¡µ
            params = {
                'pn': page,
                'pz': page_size,
                'po': '1',
                'np': '1',
                'ut': 'bd1d9ddb04089700cf9c27f6f7426281',
                'fltt': '2',
                'invt': '2',
                'fid': 'f3',
                'fs': fs_param,
                'fields': fields,
                '_': self._get_timestamp()
            }
            
            url = f"{self.base_urls['list']}/get"
            
            try:
                response = self.make_request(url, params=params)
                data = response.json()
                
                if 'data' in data and data['data'] and 'diff' in data['data']:
                    page_data = data['data']['diff']
                    if not page_data:
                        break
                    all_data.extend(page_data)
                    
                    if len(page_data) < page_size:
                        break
                else:
                    break
                    
                time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡é¢‘
                
            except Exception as e:
                print(f'è·å–ç¬¬{page}é¡µæ•°æ®å¤±è´¥: {e}')
                break
        
        if all_data:
            df = pd.DataFrame(all_data)
            # ç»Ÿä¸€å¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼
            if 'f12' in df.columns:
                df['f12'] = df['f12'].apply(BaseDataProcessor.symbol_to_stock_code)
            return df
        
        return pd.DataFrame()
    
    def get_sector_data(self, sector_type: str = 'industry', 
                       sort_field: str = 'f3') -> pd.DataFrame:
        """
        è·å–æ¿å—æ•°æ®çš„ç»Ÿä¸€æ–¹æ³•
        """
        if sector_type == 'industry':
            fs_param = 'm:90+t:2+f:!50'
        elif sector_type == 'concept':
            fs_param = 'm:90+t:3+f:!50'
        else:
            raise ValueError("sector_type must be 'industry' or 'concept'")
        
        all_data = []
        page_size = 50
        
        fields = 'f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f26,f62,f184,f66,f69,f72,f75,f78,f81,f82,f84,f85,f86,f87,f124'
        
        page = 1
        while True:
            params = {
                'pn': page,
                'pz': page_size,
                'po': '1',
                'np': '1',
                'ut': 'bd1d9ddb04089700cf9c27f6f7426281',
                'fltt': '2',
                'invt': '2',
                'fid': sort_field,
                'fs': fs_param,
                'fields': fields,
                '_': self._get_timestamp()
            }
            
            url = f"{self.base_urls['list']}/get"
            
            try:
                response = self.make_request(url, params=params)
                data = response.json()
                
                if 'data' in data and data['data'] and 'diff' in data['data']:
                    page_data = data['data']['diff']
                    if not page_data:
                        break
                    all_data.extend(page_data)
                    
                    if len(page_data) < page_size:
                        break
                else:
                    break
                    
                page += 1
                time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡é¢‘
                
            except Exception as e:
                print(f'è·å–ç¬¬{page}é¡µæ¿å—æ•°æ®å¤±è´¥: {e}')
                break
        
        if all_data:
            df = pd.DataFrame(all_data)
            print(f'âœ… æˆåŠŸè·å– {len(df)} ä¸ª{sector_type}æ¿å—æ•°æ®')
            return df
        
        return pd.DataFrame()


class OptimizedDownloadStocksList(BaseNetworkClient, BaseDataProcessor):
    """ä¼˜åŒ–åçš„è‚¡ç¥¨åˆ—è¡¨ä¸‹è½½ç±»"""
    
    def __init__(self):
        super().__init__()
        self.file_full_dir = os.path.dirname(os.path.abspath(__file__))
        self.path_dir = os.path.join(self.file_full_dir, 'stockcode_list')
        self.error_dir = os.path.join(self.file_full_dir, 'error_txt')
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.path_dir, exist_ok=True)
        os.makedirs(self.error_dir, exist_ok=True)
        
        self.all_stocklist_path = os.path.join(self.path_dir, 'all_stock_list.csv')
    
    def _download_and_process_excel(self, url: str, filename: str, 
                                   column_mappings: Dict[str, str],
                                   market_prefix: str,
                                   status: str = 'æ­£å¸¸äº¤æ˜“',
                                   extra_params: Dict = None) -> bool:
        """
        ç»Ÿä¸€çš„Excelä¸‹è½½å’Œå¤„ç†æ–¹æ³•
        """
        file_path = os.path.join(self.path_dir, f"{filename}.xls")
        csv_path = os.path.join(self.path_dir, f"{filename}.csv")
        
        try:
            # ä¸‹è½½æ–‡ä»¶
            headers = Config.SSE_CONFIG['headers'] if 'sse' in url else Config.SZSE_CONFIG['headers']
            if not self.download_file(url, file_path, headers, extra_params):
                return False
            
            # å¤„ç†Excelæ–‡ä»¶
            df = pd.read_excel(file_path, dtype=str)
            
            if df.empty:
                print(f'{filename} æ•°æ®ä¸ºç©º')
                return False
            
            # é‡å‘½ååˆ—
            df = self.rename_dataframe_columns(df, column_mappings)
            
            # æ·»åŠ å¸‚åœºå‰ç¼€
            if 'è‚¡ç¥¨ä»£ç ' in df.columns:
                df['è‚¡ç¥¨ä»£ç '] = market_prefix + df['è‚¡ç¥¨ä»£ç ']
            
            # å¤„ç†æ—¥æœŸåˆ—
            date_columns = ['ä¸Šå¸‚æ—¥æœŸ', 'ç»ˆæ­¢/æš‚åœä¸Šå¸‚æ—¥æœŸ']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')
            
            # æ·»åŠ çŠ¶æ€åˆ—
            df['ä¸Šå¸‚çŠ¶æ€'] = status
            if 'ç»ˆæ­¢/æš‚åœä¸Šå¸‚æ—¥æœŸ' not in df.columns:
                df['ç»ˆæ­¢/æš‚åœä¸Šå¸‚æ—¥æœŸ'] = None
            
            # é€‰æ‹©éœ€è¦çš„åˆ—
            required_columns = ['è‚¡ç¥¨ä»£ç ', 'åç§°', 'ä¸Šå¸‚æ—¥æœŸ', 'ä¸Šå¸‚çŠ¶æ€', 'ç»ˆæ­¢/æš‚åœä¸Šå¸‚æ—¥æœŸ']
            df = df[[col for col in required_columns if col in df.columns]]
            
            # ä¿å­˜CSV
            return self.clean_and_save_dataframe(df, csv_path)
            
        except Exception as e:
            print(f'{filename} å¤„ç†å¤±è´¥: {e}')
            return False
    
    def download_sh_stocks(self) -> bool:
        """ä¸‹è½½ä¸Šäº¤æ‰€è‚¡ç¥¨åˆ—è¡¨"""
        # ä¸»æ¿Aè‚¡
        main_url = 'http://query.sse.com.cn//sseQuery/commonExcelDd.do?sqlId=COMMON_SSE_CP_GPJCTPZ_GPLB_GP_L&type=inParams&CSRC_CODE=&STOCK_CODE=&REG_PROVINCE=&STOCK_TYPE=1&COMPANY_STATUS=2,4,5,7,8'
        main_mappings = {'Aè‚¡ä»£ç ': 'è‚¡ç¥¨ä»£ç ', 'è¯åˆ¸ç®€ç§°': 'åç§°'}
        
        # ç§‘åˆ›æ¿
        kcb_url = 'http://query.sse.com.cn//sseQuery/commonExcelDd.do?sqlId=COMMON_SSE_CP_GPJCTPZ_GPLB_GP_L&type=inParams&CSRC_CODE=&STOCK_CODE=&REG_PROVINCE=&STOCK_TYPE=8&COMPANY_STATUS=2,4,5,7,8'
        
        success1 = self._download_and_process_excel(main_url, 'ä¸Šäº¤æ‰€ä¸»æ¿Aè‚¡', main_mappings, 'sh')
        success2 = self._download_and_process_excel(kcb_url, 'ä¸Šäº¤æ‰€ç§‘åˆ›æ¿', main_mappings, 'sh')
        
        return success1 and success2
    
    def download_sz_stocks(self) -> bool:
        """ä¸‹è½½æ·±äº¤æ‰€è‚¡ç¥¨åˆ—è¡¨"""
        url = Config.SZSE_CONFIG['base_url']
        params = {'SHOWTYPE': 'xlsx', 'CATALOGID': '1110', 'TABKEY': 'tab1', 'random': random.random()}
        mappings = {'Aè‚¡ç®€ç§°': 'åç§°', 'Aè‚¡ä»£ç ': 'è‚¡ç¥¨ä»£ç ', 'Aè‚¡ä¸Šå¸‚æ—¥æœŸ': 'ä¸Šå¸‚æ—¥æœŸ'}
        
        return self._download_and_process_excel(url, 'æ·±äº¤æ‰€Aè‚¡åˆ—è¡¨', mappings, 'sz', 'æ­£å¸¸äº¤æ˜“', params)
    
    def merge_all_stocks(self) -> pd.DataFrame:
        """åˆå¹¶æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨"""
        all_files = [
            'æ·±äº¤æ‰€Aè‚¡åˆ—è¡¨.csv', 'ä¸Šäº¤æ‰€ä¸»æ¿Aè‚¡.csv', 'ä¸Šäº¤æ‰€ç§‘åˆ›æ¿.csv'
        ]
        
        all_dfs = []
        for filename in all_files:
            file_path = os.path.join(self.path_dir, filename)
            if os.path.exists(file_path):
                df = pd.read_csv(file_path, dtype={'è‚¡ç¥¨ä»£ç ': str}, encoding='utf-8')
                all_dfs.append(df)
        
        if all_dfs:
            combined_df = pd.concat(all_dfs, ignore_index=True)
            combined_df['ä¸Šå¸‚æ—¥æœŸ'] = pd.to_datetime(combined_df['ä¸Šå¸‚æ—¥æœŸ'])
            combined_df = combined_df.sort_values(['è‚¡ç¥¨ä»£ç ', 'ä¸Šå¸‚æ—¥æœŸ']).reset_index(drop=True)
            
            self.clean_and_save_dataframe(combined_df, self.all_stocklist_path)
            return combined_df
        
        return pd.DataFrame()
    
    def main(self) -> pd.DataFrame:
        """ä¸»æ‰§è¡Œæ–¹æ³•"""
        print("å¼€å§‹ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨...")
        
        # ä¸‹è½½å„ä¸ªå¸‚åœºçš„è‚¡ç¥¨åˆ—è¡¨
        self.download_sh_stocks()
        time.sleep(1)
        self.download_sz_stocks()
        time.sleep(1)
        
        # åˆå¹¶æ‰€æœ‰åˆ—è¡¨
        return self.merge_all_stocks()


class OptimizedSpiderFunc(BaseDataProcessor):
    """ä¼˜åŒ–åçš„çˆ¬è™«åŠŸèƒ½ç±»"""
    
    def __init__(self):
        self.file_full_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(self.file_full_dir)
        self.stock_hisdata_dir = os.path.join(project_root, 'data', 'datas_em')
        os.makedirs(self.stock_hisdata_dir, exist_ok=True)
        
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self.eastmoney_client = EastmoneyAPIClient()
    
    def get_realtime_market_data(self) -> pd.DataFrame:
        """è·å–å®æ—¶å¸‚åœºæ•°æ®"""
        df = self.eastmoney_client.get_stock_realtime_data([])
        
        if not df.empty:
            # åº”ç”¨å­—æ®µæ˜ å°„
            df = self.rename_dataframe_columns(df, Config.FIELD_MAPPINGS['stock_basic'])
            
            # æ·»åŠ äº¤æ˜“æ—¥æœŸ
            try:
                calendar = Get_stock_opening_calendar()
                recent_date = calendar.get_recent_trade_date()
                df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(recent_date).strftime("%Y-%m-%d")
            except:
                df['äº¤æ˜“æ—¥æœŸ'] = datetime.datetime.now().strftime("%Y-%m-%d")
            
            # è¿‡æ»¤åŒ—äº¤æ‰€è‚¡ç¥¨
            df = df[df['è‚¡ç¥¨ä»£ç '].str[:2] != 'bj']
            
            # è½¬æ¢æ•°å€¼åˆ—
            numeric_cols = ['æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 
                           'å¼€ç›˜ä»·', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼', 'æ¢æ‰‹ç‡', 'å¸‚ç›ˆç‡', 'å¸‚å‡€ç‡', 'æ¶¨é€Ÿ']
            df = self.convert_numeric_columns(df, numeric_cols)
            
            # æˆäº¤é‡è½¬æ¢ï¼ˆæ‰‹è½¬è‚¡ï¼‰
            if 'æˆäº¤é‡' in df.columns:
                df['æˆäº¤é‡'] = df['æˆäº¤é‡'] * 100
        
        return df
    
    def get_industry_data(self, sort_field: str = 'f3') -> pd.DataFrame:
        """è·å–è¡Œä¸šæ¿å—æ•°æ®"""
        df = self.eastmoney_client.get_sector_data('industry', sort_field)
        
        if not df.empty:
            # é€‰æ‹©å¹¶é‡å‘½ååˆ—
            select_cols = ['f12', 'f14', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f15', 'f16', 'f17', 'f18', 'f20', 'f21', 'f62', 'f184', 'f84', 'f124']
            available_cols = [col for col in select_cols if col in df.columns]
            df = df[available_cols]
            
            mappings = {
                'f12': 'è¡Œä¸šä»£ç ', 'f14': 'è¡Œä¸šåç§°', 'f2': 'æœ€æ–°ä»·', 'f3': 'æ¶¨è·Œå¹…',
                'f4': 'æ¶¨è·Œé¢', 'f5': 'æˆäº¤é‡', 'f6': 'æˆäº¤é¢', 'f7': 'æŒ¯å¹…',
                'f15': 'æœ€é«˜ä»·', 'f16': 'æœ€ä½ä»·', 'f17': 'å¼€ç›˜ä»·', 'f18': 'æ˜¨æ”¶ä»·',
                'f20': 'æ€»å¸‚å€¼', 'f21': 'æµé€šå¸‚å€¼', 'f62': 'ä¸»åŠ›å‡€æµå…¥', 'f184': 'ä¸»åŠ›å‡€æµå…¥å æ¯”',
                'f84': 'æ€»è‚¡æœ¬', 'f124': 'æ›´æ–°æ—¶é—´'
            }
            
            df = self.rename_dataframe_columns(df, mappings)
            
            # è½¬æ¢æ•°å€¼åˆ—
            numeric_cols = ['æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 
                           'å¼€ç›˜ä»·', 'æ˜¨æ”¶ä»·', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼', 'ä¸»åŠ›å‡€æµå…¥', 'ä¸»åŠ›å‡€æµå…¥å æ¯”', 'æ€»è‚¡æœ¬']
            df = self.convert_numeric_columns(df, numeric_cols)
        
        return df
    
    def get_concept_data(self, sort_field: str = 'f3') -> pd.DataFrame:
        """è·å–æ¦‚å¿µæ¿å—æ•°æ®"""
        df = self.eastmoney_client.get_sector_data('concept', sort_field)
        
        if not df.empty:
            # é€‰æ‹©å¹¶é‡å‘½ååˆ—
            select_cols = ['f12', 'f14', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f15', 'f16', 'f17', 'f18', 'f20', 'f21', 'f62', 'f184', 'f84', 'f124']
            available_cols = [col for col in select_cols if col in df.columns]
            df = df[available_cols]
            
            mappings = {
                'f12': 'æ¦‚å¿µä»£ç ', 'f14': 'æ¦‚å¿µåç§°', 'f2': 'æœ€æ–°ä»·', 'f3': 'æ¶¨è·Œå¹…',
                'f4': 'æ¶¨è·Œé¢', 'f5': 'æˆäº¤é‡', 'f6': 'æˆäº¤é¢', 'f7': 'æŒ¯å¹…',
                'f15': 'æœ€é«˜ä»·', 'f16': 'æœ€ä½ä»·', 'f17': 'å¼€ç›˜ä»·', 'f18': 'æ˜¨æ”¶ä»·',
                'f20': 'æ€»å¸‚å€¼', 'f21': 'æµé€šå¸‚å€¼', 'f62': 'ä¸»åŠ›å‡€æµå…¥', 'f184': 'ä¸»åŠ›å‡€æµå…¥å æ¯”',
                'f84': 'æ€»è‚¡æœ¬', 'f124': 'æ›´æ–°æ—¶é—´'
            }
            
            df = self.rename_dataframe_columns(df, mappings)
            
            # è½¬æ¢æ•°å€¼åˆ—
            numeric_cols = ['æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 
                           'å¼€ç›˜ä»·', 'æ˜¨æ”¶ä»·', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼', 'ä¸»åŠ›å‡€æµå…¥', 'ä¸»åŠ›å‡€æµå…¥å æ¯”', 'æ€»è‚¡æœ¬']
            df = self.convert_numeric_columns(df, numeric_cols)
        
        return df
    
    def get_stock_history_data(self, stock_code: str, period: str = 'æ—¥', fqt: str = '0') -> pd.DataFrame:
        """
        è·å–ä¸ªè‚¡å†å²æ•°æ®
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 'sh600519' æˆ– '600519'
        :param period: æ•°æ®å‘¨æœŸï¼Œ'æ—¥', 'å‘¨', '5åˆ†é’Ÿ', '30åˆ†é’Ÿ', '1åˆ†é’Ÿ'
        :param fqt: å¤æƒç±»å‹ï¼Œ'0'ä¸å¤æƒ, '1'å‰å¤æƒ, '2'åå¤æƒ
        :return: åŒ…å«å†å²Kçº¿æ•°æ®çš„DataFrame
        """
        if len(stock_code) == 6:
            symbol = stock_code
        elif len(stock_code) == 8:
            symbol = stock_code[2:]
        else:
            return pd.DataFrame()

        if symbol[0] == '6':
            market = '1'
        elif symbol[0] == '0' or symbol[0] == '3':
            market = '0'
        else:
            market = '0'
        secid = market + '.' + symbol

        # è®¾ç½®Kçº¿å‘¨æœŸ
        period_map = {'å‘¨': '102', 'æ—¥': '101', '5åˆ†é’Ÿ': '5', '30åˆ†é’Ÿ': '30', '1åˆ†é’Ÿ': '1'}
        klt = period_map.get(period, '101')

        # æ„å»ºAPI URL
        url = f'http://22.push2his.eastmoney.com/api/qt/stock/kline/get?secid={secid}&ut=fa5fd1943c7b386f172d6893dbfba10b&fields1=f1%2Cf2%2Cf3%2Cf4%2Cf5%2Cf6&fields2=f51%2Cf52%2Cf53%2Cf54%2Cf55%2Cf56%2Cf57%2Cf58%2Cf59%2Cf60%2Cf61&klt={klt}&fqt={fqt}&end=20500101&lmt=20000&_={int(time.time() * 1000)}'
        
        try:
            headers = {'User-Agent': random.choice(Config.USER_AGENTS)}
            resp = requests.get(url=url, headers=headers, timeout=30)
            content = resp.content.decode('utf-8')
            
            if 'data' in content:
                data = resp.json()['data']['klines']
                lst_data = []

                for i in data:
                    lst_i = i.split(',')
                    lst_data.append(lst_i)
                
                df = pd.DataFrame(lst_data)
                df.columns = ['äº¤æ˜“æ—¥æœŸ', 'å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡']
                
                # è½¬æ¢æ•°å€¼åˆ—
                numeric_cols = ['å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡']
                df = self.convert_numeric_columns(df, numeric_cols)
                
                return df
            else:
                print(f'è·å–å†å²è¡Œæƒ…å‡ºé”™ï¼è‚¡ç¥¨ä»£ç : {stock_code}')
                return pd.DataFrame()
                
        except Exception as e:
            print(f'è·å–å†å²è¡Œæƒ…å¼‚å¸¸ï¼è‚¡ç¥¨ä»£ç : {stock_code}, é”™è¯¯: {str(e)}')
            return pd.DataFrame()

    def get_stock_history_data_with_market_cap_from_163(self, stock_code: str, start_date: str = '20000101', end_date: str = None) -> pd.DataFrame:
        """
        ä»ç½‘æ˜“163è·å–åŒ…å«æµé€šå¸‚å€¼çš„å†å²æ•°æ®
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 'sh600519' æˆ– '600519'
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYYMMDDï¼Œé»˜è®¤ä¸ºä»Šå¤©
        :return: åŒ…å«å†å²Kçº¿æ•°æ®å’Œæµé€šå¸‚å€¼çš„DataFrame
        """
        import datetime
        
        if end_date is None:
            end_date = datetime.datetime.now().strftime('%Y%m%d')
        
        # å¤„ç†è‚¡ç¥¨ä»£ç 
        if len(stock_code) == 8 and stock_code.startswith(('sh', 'sz')):
            code = stock_code[2:]
            code_prefix = stock_code[:2]
        elif len(stock_code) == 6:
            code = stock_code
            # æ ¹æ®ä»£ç åˆ¤æ–­å¸‚åœº
            if code[0] == '6':
                code_prefix = 'sh'
            else:
                code_prefix = 'sz'
        else:
            return pd.DataFrame()
        
        # ç½‘æ˜“163çš„å¸‚åœºä»£ç ï¼ˆä¸ä¸œè´¢ç›¸åï¼‰
        if code[0] == '6':
            market_code = '0'  # ä¸Šäº¤æ‰€
        else:
            market_code = '1'  # æ·±äº¤æ‰€
        
        # æ„å»ºç½‘æ˜“163 API URL - åŒ…å«æµé€šå¸‚å€¼å­—æ®µMCAP
        url = f"http://quotes.money.163.com/service/chddata.html?code={market_code}{code}&start={start_date}&end={end_date}&fields=TCLOSE;HIGH;LOW;TOPEN;LCLOSE;CHG;PCHG;TURNOVER;VOTURNOVER;VATURNOVER;TCAP;MCAP"
        
        try:
            headers = {'User-Agent': random.choice(Config.USER_AGENTS)}
            response = requests.get(url=url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # å°†å“åº”å†…å®¹ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶å¹¶è¯»å–
            import tempfile
            import os
            
            with tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix='.csv') as temp_file:
                temp_file.write(response.content)
                temp_path = temp_file.name
            
            try:
                # è¯»å–CSVæ•°æ®
                df = pd.read_csv(temp_path, dtype={'è‚¡ç¥¨ä»£ç ': str}, sep=',', encoding='gbk')
                
                if len(df) >= 1:
                    # å¤„ç†æ•°æ®
                    df = df.replace('None', 0)
                    df = df.fillna(value=0)
                    
                    # é‡å‘½ååˆ—å
                    rename_dict = {'æ—¥æœŸ': 'äº¤æ˜“æ—¥æœŸ', 'å‰æ”¶ç›˜': 'å‰æ”¶ç›˜ä»·', 'æˆäº¤é‡‘é¢': 'æˆäº¤é¢'}
                    df.rename(columns=rename_dict, inplace=True)
                    
                    # å¤„ç†è‚¡ç¥¨ä»£ç åˆ—
                    if 'è‚¡ç¥¨ä»£ç ' in df.columns:
                        df['è‚¡ç¥¨ä»£ç '] = df['è‚¡ç¥¨ä»£ç '].str.strip()
                        df['è‚¡ç¥¨ä»£ç '] = code_prefix + df['è‚¡ç¥¨ä»£ç '].str[1:]
                    else:
                        df['è‚¡ç¥¨ä»£ç '] = stock_code
                    
                    # è½¬æ¢æ•°å€¼åˆ—
                    numeric_cols = ['æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'å¼€ç›˜ä»·', 'å‰æ”¶ç›˜ä»·', 'æ¶¨è·Œé¢', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼']
                    available_numeric_cols = [col for col in numeric_cols if col in df.columns]
                    df[available_numeric_cols] = df[available_numeric_cols].astype(float)
                    
                    # å¤„ç†æ—¥æœŸåˆ—
                    if 'äº¤æ˜“æ—¥æœŸ' in df.columns:
                        df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ'])
                        df = df.sort_values(by=['äº¤æ˜“æ—¥æœŸ'], ascending=True)
                        df.reset_index(drop=True, inplace=True)
                        # å°†æ—¥æœŸè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œä¸ä¸œè´¢APIä¿æŒä¸€è‡´
                        df['äº¤æ˜“æ—¥æœŸ'] = df['äº¤æ˜“æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
                    
                    return df
                else:
                    return pd.DataFrame()
                    
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    
        except Exception as e:
            print(f'ä»ç½‘æ˜“163è·å–å†å²æ•°æ®å¼‚å¸¸ï¼è‚¡ç¥¨ä»£ç : {stock_code}, é”™è¯¯: {str(e)}')
            return pd.DataFrame()

    def get_stock_history_data_with_real_market_cap(self, stock_code: str, period: str = 'æ—¥', fqt: str = '0') -> pd.DataFrame:
        """
        è·å–åŒ…å«çœŸå®æµé€šå¸‚å€¼çš„å†å²æ•°æ®
        é€šè¿‡è·å–å½“å‰æµé€šè‚¡æœ¬ï¼Œè®¡ç®—å†å²å„æ—¥çš„æµé€šå¸‚å€¼
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 'sh600519' æˆ– '600519'
        :param period: æ•°æ®å‘¨æœŸï¼Œ'æ—¥', 'å‘¨', '5åˆ†é’Ÿ', '30åˆ†é’Ÿ', '1åˆ†é’Ÿ'
        :param fqt: å¤æƒç±»å‹ï¼Œ'0'ä¸å¤æƒ, '1'å‰å¤æƒ, '2'åå¤æƒ
        :return: åŒ…å«å†å²Kçº¿æ•°æ®å’Œæµé€šå¸‚å€¼çš„DataFrame
        """
        # å…ˆè·å–åŸºç¡€å†å²æ•°æ®
        df_history = self.get_stock_history_data(stock_code, period, fqt)
        
        if df_history.empty:
            return df_history
        
        # è·å–å½“å‰è‚¡ç¥¨çš„æµé€šè‚¡æœ¬ä¿¡æ¯
        try:
            # ç›´æ¥ä½¿ç”¨ä¸œè´¢å•è‚¡ç¥¨æŸ¥è¯¢APIè·å–æµé€šå¸‚å€¼
            if len(stock_code) == 6:
                symbol = stock_code
            elif len(stock_code) == 8:
                symbol = stock_code[2:]
            else:
                df_history['æµé€šå¸‚å€¼'] = None
                return df_history
            
            if symbol[0] == '6':
                market = '1'
            elif symbol[0] in ['0', '3']:
                market = '0'
            else:
                market = '0'
            secid = market + '.' + symbol
            
            # ä½¿ç”¨ä¸œè´¢å•è‚¡ç¥¨æŸ¥è¯¢APIè·å–æµé€šè‚¡æœ¬
            info_url = f'http://push2.eastmoney.com/api/qt/stock/get?ut=fa5fd1943c7b386f172d6893dbfba10b&invt=2&fltt=1&fields=f84,f85&secid={secid}&_={int(time.time() * 1000)}'
            
            headers = {'User-Agent': random.choice(Config.USER_AGENTS)}
            resp = requests.get(url=info_url, headers=headers, timeout=30)
            
            if resp.status_code == 200:
                info_data = resp.json()
                if 'data' in info_data and info_data['data']:
                    stock_info = info_data['data']
                    liutong_gub = stock_info.get('f85', 0)  # æµé€šè‚¡æœ¬ï¼ˆè‚¡ï¼‰
                    
                    if liutong_gub:
                        try:
                            liutong_gub = float(liutong_gub)
                            if liutong_gub > 0:
                                # ç›´æ¥ç”¨æµé€šè‚¡æœ¬è®¡ç®—æµé€šå¸‚å€¼ = æ”¶ç›˜ä»· * æµé€šè‚¡æœ¬
                                df_history['æµé€šå¸‚å€¼'] = df_history['æ”¶ç›˜ä»·'] * liutong_gub
                                
                                # è½¬æ¢æ•°å€¼åˆ—
                                numeric_cols = ['å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡', 'æµé€šå¸‚å€¼']
                                df_history = self.convert_numeric_columns(df_history, numeric_cols)
                                
                                return df_history
                            else:
                                # å¦‚æœæµé€šè‚¡æœ¬ä¸º0ï¼Œè®¾ç½®æµé€šå¸‚å€¼ä¸ºç©º
                                df_history['æµé€šå¸‚å€¼'] = None
                                return df_history
                        except (ValueError, TypeError):
                            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè®¾ç½®æµé€šå¸‚å€¼ä¸ºç©º
                            df_history['æµé€šå¸‚å€¼'] = None
                            return df_history
                    else:
                        # å¦‚æœè·å–ä¸åˆ°æµé€šè‚¡æœ¬æ•°æ®ï¼Œè®¾ç½®æµé€šå¸‚å€¼ä¸ºç©º
                        df_history['æµé€šå¸‚å€¼'] = None
                        return df_history
                else:
                    # å¦‚æœAPIè¿”å›æ— æ•ˆæ•°æ®ï¼Œè®¾ç½®æµé€šå¸‚å€¼ä¸ºç©º
                    df_history['æµé€šå¸‚å€¼'] = None
                    return df_history
            else:
                # å¦‚æœAPIè¯·æ±‚å¤±è´¥ï¼Œè®¾ç½®æµé€šå¸‚å€¼ä¸ºç©º
                df_history['æµé€šå¸‚å€¼'] = None
                return df_history
                
        except Exception as e:
            # å¦‚æœè·å–æµé€šè‚¡æœ¬å¤±è´¥ï¼Œè®¾ç½®æµé€šå¸‚å€¼ä¸ºç©ºä½†ä¸å½±å“å…¶ä»–æ•°æ®
            df_history['æµé€šå¸‚å€¼'] = None
            print(f'è·å–æµé€šå¸‚å€¼ä¿¡æ¯å¤±è´¥ {stock_code}: {e}')
            return df_history

    def download_all_stocks_history_data(self) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰Aè‚¡å†å²æ•°æ®åˆ°data/datas_emç›®å½•
        """
        print("ğŸ”„ å¼€å§‹ä¸‹è½½æ‰€æœ‰Aè‚¡å†å²æ•°æ®...")
        
        try:
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            downloader = OptimizedDownloadStocksList()
            stock_list_path = downloader.all_stocklist_path
            
            # æ£€æŸ¥è‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(stock_list_path):
                print("âŒ è‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œè‚¡ç¥¨åˆ—è¡¨ä¸‹è½½")
                return False
            
            # è¯»å–è‚¡ç¥¨åˆ—è¡¨
            df_stocks = pd.read_csv(stock_list_path, dtype={'è‚¡ç¥¨ä»£ç ': str}, encoding='utf-8')
            total_stocks = len(df_stocks)
            
            print(f"ğŸ“Š å…±éœ€ä¸‹è½½ {total_stocks} åªè‚¡ç¥¨çš„å†å²æ•°æ®")
            
            success_count = 0
            error_count = 0
            
            for i, row in df_stocks.iterrows():
                try:
                    code = row['è‚¡ç¥¨ä»£ç ']
                    print(f"ğŸ”„ æ­£åœ¨å¤„ç†: {code} ({i+1}/{total_stocks})")
                    
                    # è·å–å†å²æ•°æ®ï¼ˆåŒ…å«çœŸå®æµé€šå¸‚å€¼ï¼ŒåŸºäºå½“å‰æµé€šè‚¡æœ¬è®¡ç®—ï¼‰
                    df_code = self.get_stock_history_data_with_real_market_cap(stock_code=code)
                    
                    if not df_code.empty:
                        # ä¿å­˜æ•°æ®
                        save_path = os.path.join(self.stock_hisdata_dir, f'{code}.csv')
                        self.clean_and_save_dataframe(df_code, save_path)
                        
                        success_count += 1
                        print(f'âœ… {code} æ•°æ®ä¿å­˜å®Œæˆ')
                        
                        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡é¢‘
                        time.sleep(0.5)
                    else:
                        print(f'âŒ {code} æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®')
                        error_count += 1
                        
                except Exception as e:
                    print(f'âŒ {code} å¤„ç†å‡ºé”™: {e}')
                    error_count += 1
                    continue
            
            print(f"\nğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡:")
            print(f"   âœ… æˆåŠŸ: {success_count} åª")
            print(f"   âŒ å¤±è´¥: {error_count} åª")
            print(f"   ğŸ“ æ•°æ®ä¿å­˜ç›®å½•: {self.stock_hisdata_dir}")
            
            return success_count > 0
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False

    def get_hot_concepts_from_eastmoney(self, limit: int = 50) -> pd.DataFrame:
        """
        è·å–çƒ­é—¨æ¦‚å¿µæ¿å—æ’è¡Œ
        :param limit: è¿”å›æ•°é‡é™åˆ¶
        :return: åŒ…å«çƒ­é—¨æ¦‚å¿µçš„DataFrame
        """
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'
        }
        
        timestamp = int(time.time() * 1000)
        
        # çƒ­é—¨æ¦‚å¿µAPIï¼ˆæŒ‰æ¶¨è·Œå¹…æ’åºï¼‰
        fields = 'f12,f14,f2,f3,f4,f5,f6,f7,f62,f184,f104,f105,f140,f141,f136'
        url = f'http://push2.eastmoney.com/api/qt/clist/get?pn=1&pz={limit}&po=1&np=1&ut=bd1d9ddb04089700cf9c27f6f7426281&fltt=2&invt=2&fid=f3&fs=m:90+t:3+f:!50&fields={fields}&_={timestamp}'

        try:
            import requests
            resp = requests.get(url=url, headers=headers)
            resp_json = resp.json()
            
            if 'data' in resp_json and resp_json['data'] is not None:
                df = pd.DataFrame(resp_json['data']['diff'])
                
                if not df.empty:
                    # é€‰æ‹©å¹¶é‡å‘½ååˆ—
                    df = df[['f12', 'f14', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f62', 'f184', 'f104', 'f105']]
                    
                    rename_dict = {
                        'f12': 'æ¦‚å¿µä»£ç ',
                        'f14': 'æ¦‚å¿µåç§°', 
                        'f2': 'æœ€æ–°æŒ‡æ•°',
                        'f3': 'æ¶¨è·Œå¹…',
                        'f4': 'æ¶¨è·Œé¢',
                        'f5': 'æˆäº¤é‡',
                        'f6': 'æˆäº¤é¢',
                        'f7': 'æŒ¯å¹…',
                        'f62': 'ä¸»åŠ›å‡€æµå…¥',
                        'f184': 'ä¸»åŠ›å‡€æµå…¥å æ¯”',
                        'f104': 'ä¸Šæ¶¨å®¶æ•°',
                        'f105': 'ä¸‹è·Œå®¶æ•°'
                    }
                    
                    df.rename(columns=rename_dict, inplace=True)
                    
                    # è½¬æ¢æ•°æ®ç±»å‹
                    numeric_cols = ['æœ€æ–°æŒ‡æ•°', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'ä¸»åŠ›å‡€æµå…¥', 'ä¸»åŠ›å‡€æµå…¥å æ¯”', 'ä¸Šæ¶¨å®¶æ•°', 'ä¸‹è·Œå®¶æ•°']
                    df[numeric_cols] = df[numeric_cols].astype(float)
                    
                    return df
            
            print('è·å–çƒ­é—¨æ¦‚å¿µæ•°æ®å¤±è´¥')
            return pd.DataFrame()
            
        except Exception as e:
            print(f'è·å–çƒ­é—¨æ¦‚å¿µæ•°æ®å‡ºé”™ï¼š{e}')
            return pd.DataFrame()

    def get_stock_industry_info_from_eastmoney(self, stock_code: str) -> dict:
        """
        è·å–ä¸ªè‚¡æ‰€å±è¡Œä¸šå’Œæ¦‚å¿µä¿¡æ¯
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 'sh600519' æˆ– '600519'
        :return: åŒ…å«è¡Œä¸šå’Œæ¦‚å¿µä¿¡æ¯çš„å­—å…¸
        """
        if len(stock_code) == 6:
            symbol = stock_code
        elif len(stock_code) == 8:
            symbol = stock_code[2:]
        else:
            return {}

        if symbol[0] == '6':
            market = '1'
        elif symbol[0] == '0' or symbol[0] == '3':
            market = '0'
        else:
            market = '0'
        secid = market + '.' + symbol

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'
        }

        timestamp = int(time.time() * 1000)
        
        try:
            import requests
            # ç¬¬ä¸€æ­¥ï¼šè·å–åŸºæœ¬ä¿¡æ¯
            basic_url = f'http://push2.eastmoney.com/api/qt/stock/get?secid={secid}&ut=fa5fd1943c7b386f172d6893dbfba10b&fields=f57,f58,f84,f85,f86,f87,f127&_={timestamp}'
            
            resp = requests.get(url=basic_url, headers=headers)
            resp_json = resp.json()
            
            stock_info = {
                'è‚¡ç¥¨ä»£ç ': stock_code,
                'è‚¡ç¥¨åç§°': '',
                'æ‰€å±è¡Œä¸š': '',
                'æ¦‚å¿µæ¿å—': '',
                'åœ°åŒº': '',
                'æ€»è‚¡æœ¬': 0,
                'æµé€šè‚¡': 0,
                'æ¯è‚¡æ”¶ç›Š': 0,
                'æ¯è‚¡å‡€èµ„äº§': 0
            }
            
            if 'data' in resp_json and resp_json['data'] is not None:
                data = resp_json['data']
                
                stock_info.update({
                    'è‚¡ç¥¨åç§°': data.get('f58', ''),
                    'æ‰€å±è¡Œä¸š': data.get('f127', ''),
                    'æ€»è‚¡æœ¬': data.get('f84', 0),
                    'æµé€šè‚¡': data.get('f85', 0),
                    'æ¯è‚¡æ”¶ç›Š': data.get('f86', 0),
                    'æ¯è‚¡å‡€èµ„äº§': data.get('f87', 0)
                })
            
            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨å¤šç§æ–¹æ³•è·å–æ¦‚å¿µæ¿å—å’Œåœ°åŒºä¿¡æ¯
            concept_found = False
            region_found = False
            
            # æ–¹æ³•1ï¼šä½¿ç”¨å®Œæ•´å­—æ®µçš„è‚¡ç¥¨è¯¦æƒ…API
            try:
                detail_url = f'http://push2.eastmoney.com/api/qt/stock/get?secid={secid}&ut=fa5fd1943c7b386f172d6893dbfba10b&fields=f116,f117,f127,f128,f136,f173&_={timestamp}'
                
                detail_resp = requests.get(url=detail_url, headers=headers)
                if detail_resp.status_code == 200:
                    detail_data = detail_resp.json()
                    
                    if 'data' in detail_data and detail_data['data']:
                        data = detail_data['data']
                        
                        # å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µ
                        concept_fields = ['f128', 'f116', 'f173']
                        region_fields = ['f136', 'f117']
                        
                        # å¤„ç†åœ°åŒºä¿¡æ¯ï¼ˆf128å­—æ®µå®é™…æ˜¯åœ°åŒºæ¿å—ï¼‰
                        if 'f128' in data:
                            region_board = data['f128']
                            if region_board and str(region_board) not in ['-', '0', '']:
                                # ä»"è´µå·æ¿å—"æå–"è´µå·"
                                region_name = str(region_board).replace('æ¿å—', '')
                                stock_info['åœ°åŒº'] = region_name
                                region_found = True
                        
                        # å°è¯•è·å–çœŸæ­£çš„æ¦‚å¿µæ¿å—ä¿¡æ¯
                        if not concept_found:
                            try:
                                # ä½¿ç”¨ä¸ªè‚¡æ‰€å±æ¦‚å¿µæ¿å—API
                                concept_api_url = f'http://push2.eastmoney.com/api/qt/slist/get?spt=1&fltt=2&invt=2&pi=0&pz=200&po=1&np=1&ut=bd1d9ddb04089700cf9c27f6f7426281&fields=f12,f14,f103&fid=f3&secid={secid}&_={timestamp}'
                                
                                concept_resp = requests.get(url=concept_api_url, headers=headers)
                                if concept_resp.status_code == 200:
                                    concept_data = concept_resp.json()
                                    
                                    if 'data' in concept_data and concept_data['data'] and 'diff' in concept_data['data']:
                                        concepts = concept_data['data']['diff']
                                        
                                        # æŸ¥æ‰¾å½“å‰è‚¡ç¥¨çš„æ¦‚å¿µä¿¡æ¯
                                        for item in concepts:
                                            if item.get('f12') == symbol:  # æ‰¾åˆ°å½“å‰è‚¡ç¥¨
                                                concept_list = item.get('f103', '')
                                                if concept_list and concept_list != '-':
                                                    stock_info['æ¦‚å¿µæ¿å—'] = concept_list
                                                    concept_found = True
                                                    break
                            except Exception as e:
                                pass
                        
                        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°æ¦‚å¿µæ¿å—ï¼Œè®¾ä¸ºç©º
                        if not concept_found:
                            stock_info['æ¦‚å¿µæ¿å—'] = ''
                
            except Exception as e:
                pass
            
            # æ–¹æ³•2ï¼šå¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œä»è‚¡ç¥¨åˆ—è¡¨ä¸­æŸ¥æ‰¾
            if not concept_found or not region_found:
                try:
                    # ä½¿ç”¨åŒ…å«æ›´å¤šå­—æ®µçš„è‚¡ç¥¨åˆ—è¡¨API
                    list_url = f'http://push2.eastmoney.com/api/qt/clist/get?pn=1&pz=5000&po=1&np=1&ut=bd1d9ddb04089700cf9c27f6f7426281&fltt=2&invt=2&fid=f3&fs=m:0+t:6+f:!2,m:0+t:13+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:7+f:!2,m:1+t:3+f:!2&fields=f12,f14,f116,f117,f127,f128,f136,f173&_={timestamp}'
                    
                    list_resp = requests.get(url=list_url, headers=headers)
                    if list_resp.status_code == 200:
                        list_data = list_resp.json()
                        
                        if 'data' in list_data and list_data['data'] and 'diff' in list_data['data']:
                            stocks = list_data['data']['diff']
                            
                            # æŸ¥æ‰¾å½“å‰è‚¡ç¥¨
                            for stock in stocks:
                                if stock.get('f12') == symbol:  # f12æ˜¯è‚¡ç¥¨ä»£ç 
                                    # å¤„ç†åœ°åŒºä¿¡æ¯ï¼ˆf128æ˜¯åœ°åŒºæ¿å—ï¼‰
                                    if not region_found and 'f128' in stock:
                                        region_board = stock['f128']
                                        if region_board and str(region_board) not in ['-', '0', '']:
                                            # ä»"è´µå·æ¿å—"æå–"è´µå·"
                                            region_name = str(region_board).replace('æ¿å—', '')
                                            stock_info['åœ°åŒº'] = region_name
                                            region_found = True
                                    
                                    # å¦‚æœè¿˜æ²¡æ‰¾åˆ°æ¦‚å¿µæ¿å—ï¼Œå°è¯•è·å–
                                    if not concept_found:
                                        try:
                                            # ä½¿ç”¨ä¸ªè‚¡æ‰€å±æ¦‚å¿µæ¿å—API
                                            concept_api_url = f'http://push2.eastmoney.com/api/qt/slist/get?spt=1&fltt=2&invt=2&pi=0&pz=200&po=1&np=1&ut=bd1d9ddb04089700cf9c27f6f7426281&fields=f12,f14,f103&fid=f3&secid={secid}&_={timestamp}'
                                            
                                            concept_resp = requests.get(url=concept_api_url, headers=headers)
                                            if concept_resp.status_code == 200:
                                                concept_data = concept_resp.json()
                                                
                                                if 'data' in concept_data and concept_data['data'] and 'diff' in concept_data['data']:
                                                    concepts = concept_data['data']['diff']
                                                    
                                                    # æŸ¥æ‰¾å½“å‰è‚¡ç¥¨çš„æ¦‚å¿µä¿¡æ¯
                                                    for item in concepts:
                                                        if item.get('f12') == symbol:  # æ‰¾åˆ°å½“å‰è‚¡ç¥¨
                                                            concept_list = item.get('f103', '')
                                                            if concept_list and concept_list != '-':
                                                                stock_info['æ¦‚å¿µæ¿å—'] = concept_list
                                                                concept_found = True
                                                                break
                                        except Exception as e:
                                            pass
                                    
                                    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè®¾ä¸ºç©º
                                    if not concept_found:
                                        stock_info['æ¦‚å¿µæ¿å—'] = ''
                                    
                                    break
                
                except Exception as e:
                    pass
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰è·å–åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not stock_info['æ¦‚å¿µæ¿å—']:
                stock_info['æ¦‚å¿µæ¿å—'] = ''
            if not stock_info['åœ°åŒº']:
                stock_info['åœ°åŒº'] = ''
                
            return stock_info
            
        except Exception as e:
            print(f'è·å–{stock_code}è¡Œä¸šæ¦‚å¿µä¿¡æ¯å‡ºé”™ï¼š{e}')
            return {}

    def get_historical_sector_data_from_eastmoney(self, sector_code: str, sector_type: str = 'industry', 
                                                  trading_days: int = 30, period: str = 'daily', 
                                                  is_incremental: bool = False, save_dir: str = None) -> pd.DataFrame:
        """
        è·å–æ¿å—å†å²æ•°æ®
        :param sector_code: æ¿å—ä»£ç 
        :param sector_type: æ¿å—ç±»å‹ï¼Œ'industry'è¡Œä¸šæ¿å— æˆ– 'concept'æ¦‚å¿µæ¿å—
        :param trading_days: è·å–æœ€è¿‘å¤šå°‘ä¸ªäº¤æ˜“æ—¥ï¼Œé»˜è®¤30ä¸ªäº¤æ˜“æ—¥
        :param period: æ•°æ®å‘¨æœŸï¼Œ'daily'æ—¥çº¿ 'weekly'å‘¨çº¿ 'monthly'æœˆçº¿
        :param is_incremental: æ˜¯å¦ä¸ºå¢é‡æ›´æ–°æ¨¡å¼
        :param save_dir: ä¿å­˜ç›®å½•ï¼Œç”¨äºå¢é‡æ›´æ–°æ—¶æŸ¥æ‰¾ç°æœ‰æ•°æ®
        :return: åŒ…å«å†å²æ•°æ®çš„DataFrame
        """
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
            'Referer': 'http://quote.eastmoney.com/'
        }
        
        # å¢é‡æ›´æ–°é€»è¾‘
        start_date_override = None
        if is_incremental and save_dir:
            # æŸ¥æ‰¾ç°æœ‰æ•°æ®æ–‡ä»¶
            import os
            sector_name = f"æ¿å—{sector_code}"  # ä¸´æ—¶åç§°ï¼Œå¯èƒ½éœ€è¦è·å–çœŸå®åç§°
            possible_filenames = [
                f"{sector_name}({sector_code})_daily_å†å²æ•°æ®.csv",
                f"{sector_code}_daily_å†å²æ•°æ®.csv"
            ]
            
            existing_file = None
            for filename in possible_filenames:
                file_path = os.path.join(save_dir, filename)
                if os.path.exists(file_path):
                    existing_file = file_path
                    break
            
            if existing_file:
                try:
                    existing_df = pd.read_csv(existing_file, encoding='utf-8-sig')
                    if len(existing_df) > 0 and 'æ—¥æœŸ' in existing_df.columns:
                        latest_date = existing_df['æ—¥æœŸ'].max()
                        # ä»æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹è·å–
                        latest_dt = datetime.datetime.strptime(latest_date, '%Y-%m-%d')
                        next_day = latest_dt + datetime.timedelta(days=1)
                        start_date_override = next_day.strftime('%Y%m%d')
                        print(f"å¢é‡æ›´æ–°æ¨¡å¼: ä» {latest_date} ä¹‹åå¼€å§‹è·å–æ•°æ®")
                except Exception as e:
                    print(f"è¯»å–ç°æœ‰æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨å¸¸è§„è·å–æ¨¡å¼: {e}")
        
        try:
            import requests
            # è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆåŸºäºäº¤æ˜“æ—¥æ•°é‡ï¼‰
            end_date = datetime.datetime.now().strftime('%Y%m%d')
            
            # ä½¿ç”¨å¢é‡æ›´æ–°çš„èµ·å§‹æ—¥æœŸè¦†ç›–
            if start_date_override:
                start_date = start_date_override
                print(f"å¢é‡æ›´æ–°æ•°æ®ï¼Œæ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
            elif trading_days is None or trading_days >= 1000:
                # è·å–å…¨éƒ¨å†å²æ•°æ®ï¼Œè®¾ç½®ä¸€ä¸ªå¾ˆæ—©çš„å¼€å§‹æ—¥æœŸ
                start_date = '20100101'  # ä»2010å¹´å¼€å§‹ï¼Œæ¶µç›–å¤§éƒ¨åˆ†æ¿å—çš„å†å²
                print(f"è·å–å…¨éƒ¨å†å²æ•°æ®ï¼Œæ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
            else:
                # ä¸ºäº†ç¡®ä¿è·å–åˆ°è¶³å¤Ÿçš„äº¤æ˜“æ—¥ï¼Œå®é™…è·å–å¤©æ•°è¦å¤šä¸€äº›ï¼ˆè€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
                actual_days = trading_days * 2  # å¤§çº¦ä¸¤å€å¤©æ•°ç¡®ä¿åŒ…å«è¶³å¤Ÿäº¤æ˜“æ—¥
                start_dt = datetime.datetime.now() - datetime.timedelta(days=actual_days)
                start_date = start_dt.strftime('%Y%m%d')
                print(f"è·å–æœ€è¿‘{trading_days}ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼Œæ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
            
            # æ ¹æ®å‘¨æœŸè®¾ç½®å‚æ•°
            klt_map = {'daily': '101', 'weekly': '102', 'monthly': '103'}
            klt = klt_map.get(period, '101')
            
            # æ ¹æ®æ¿å—ç±»å‹è®¾ç½®secidå‰ç¼€
            if sector_type == 'industry':
                secid = f"90.{sector_code}"  # è¡Œä¸šæ¿å—ä½¿ç”¨90å‰ç¼€
            else:
                secid = f"90.{sector_code}"  # æ¦‚å¿µæ¿å—ä¹Ÿä½¿ç”¨90å‰ç¼€
            
            # æ„å»ºå†å²æ•°æ®API URL
            if trading_days is None or trading_days >= 1000:
                # è·å–å…¨éƒ¨å†å²æ•°æ®ï¼Œä¸é™åˆ¶æ•°é‡
                url = f'http://push2his.eastmoney.com/api/qt/stock/kline/get?secid={secid}&ut=fa5fd1943c7b386f172d6893dbfba10b&fields1=f1,f2,f3,f4,f5,f6&fields2=f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61&klt={klt}&fqt=1&beg={start_date}&end={end_date}&_={int(time.time() * 1000)}'
            else:
                # è·å–æŒ‡å®šæ•°é‡çš„æ•°æ®
                url = f'http://push2his.eastmoney.com/api/qt/stock/kline/get?secid={secid}&ut=fa5fd1943c7b386f172d6893dbfba10b&fields1=f1,f2,f3,f4,f5,f6&fields2=f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61&klt={klt}&fqt=1&beg={start_date}&end={end_date}&lmt={trading_days}&_={int(time.time() * 1000)}'
            
            print(f"æ­£åœ¨è·å–æ¿å— {sector_code} çš„å†å²æ•°æ®...")
            print(f"è¯·æ±‚URL: {url}")
            
            resp = requests.get(url=url, headers=headers, timeout=30)
            
            if resp.status_code != 200:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
                return pd.DataFrame()
                
            resp_json = resp.json()
            
            if 'data' in resp_json and resp_json['data'] is not None:
                klines = resp_json['data'].get('klines', [])
                
                if not klines:
                    print(f"æ¿å— {sector_code} æ— å†å²æ•°æ®")
                    return pd.DataFrame()
                
                # è§£æKçº¿æ•°æ®
                data_list = []
                for kline in klines:
                    # Kçº¿æ•°æ®æ ¼å¼ï¼šæ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…,æ¶¨è·Œå¹…,æ¶¨è·Œé¢,æ¢æ‰‹ç‡
                    parts = kline.split(',')
                    if len(parts) >= 11:
                        data_list.append({
                            'æ—¥æœŸ': parts[0],
                            'å¼€ç›˜ä»·': float(parts[1]) if parts[1] != '-' else 0,
                            'æ”¶ç›˜ä»·': float(parts[2]) if parts[2] != '-' else 0,
                            'æœ€é«˜ä»·': float(parts[3]) if parts[3] != '-' else 0,
                            'æœ€ä½ä»·': float(parts[4]) if parts[4] != '-' else 0,
                            'æˆäº¤é‡': float(parts[5]) if parts[5] != '-' else 0,
                            'æˆäº¤é¢': float(parts[6]) if parts[6] != '-' else 0,
                            'æŒ¯å¹…': float(parts[7]) if parts[7] != '-' else 0,
                            'æ¶¨è·Œå¹…': float(parts[8]) if parts[8] != '-' else 0,
                            'æ¶¨è·Œé¢': float(parts[9]) if parts[9] != '-' else 0,
                            'æ¢æ‰‹ç‡': float(parts[10]) if parts[10] != '-' else 0
                        })
                
                if data_list:
                    df = pd.DataFrame(data_list)
                    # æ·»åŠ æ¿å—ä¿¡æ¯
                    df['æ¿å—ä»£ç '] = sector_code
                    df['æ¿å—ç±»å‹'] = sector_type
                    
                    # æŒ‰æ—¥æœŸæ’åº
                    df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
                    
                    print(f"æˆåŠŸè·å–æ¿å— {sector_code} å†å²æ•°æ® {len(df)} æ¡")
                    return df
                else:
                    print(f"æ¿å— {sector_code} æ•°æ®è§£æå¤±è´¥")
                    return pd.DataFrame()
            else:
                print(f"æ¿å— {sector_code} å“åº”æ•°æ®æ ¼å¼é”™è¯¯")
                return pd.DataFrame()
                
        except Exception as e:
            print(f'è·å–æ¿å— {sector_code} å†å²æ•°æ®å‡ºé”™ï¼š{e}')
            return pd.DataFrame()

    def get_all_sectors_historical_data(self, sector_type: str = 'industry', 
                                       trading_days: int = 30, period: str = 'daily', 
                                       save_dir: str = None, is_incremental: bool = False) -> dict:
        """
        æ‰¹é‡è·å–æ‰€æœ‰æ¿å—çš„å†å²æ•°æ®
        :param sector_type: æ¿å—ç±»å‹ï¼Œ'industry'è¡Œä¸šæ¿å— æˆ– 'concept'æ¦‚å¿µæ¿å—
        :param trading_days: è·å–æœ€è¿‘å¤šå°‘ä¸ªäº¤æ˜“æ—¥ï¼Œé»˜è®¤30ä¸ªäº¤æ˜“æ—¥
        :param period: æ•°æ®å‘¨æœŸï¼Œ'daily'æ—¥çº¿ 'weekly'å‘¨çº¿ 'monthly'æœˆçº¿
        :param save_dir: ä¿å­˜ç›®å½•ï¼Œå¦‚æœæä¾›åˆ™ä¿å­˜CSVæ–‡ä»¶
        :param is_incremental: æ˜¯å¦ä¸ºå¢é‡æ›´æ–°æ¨¡å¼
        :return: åŒ…å«æ‰€æœ‰æ¿å—æ•°æ®çš„å­—å…¸
        """
        print(f"å¼€å§‹æ‰¹é‡è·å–{sector_type}æ¿å—å†å²æ•°æ®...")
        
        # é¦–å…ˆè·å–æ‰€æœ‰æ¿å—åˆ—è¡¨
        if sector_type == 'industry':
            sectors_df = self.get_industry_data()
            code_col = 'è¡Œä¸šä»£ç '
            name_col = 'è¡Œä¸šåç§°'
        else:
            sectors_df = self.get_concept_data()
            code_col = 'æ¦‚å¿µä»£ç '
            name_col = 'æ¦‚å¿µåç§°'
        
        if sectors_df.empty:
            print(f"è·å–{sector_type}æ¿å—åˆ—è¡¨å¤±è´¥")
            return {}
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if save_dir:
            import os
            os.makedirs(save_dir, exist_ok=True)
        
        all_data = {}
        successful_count = 0
        total_count = len(sectors_df)
        
        print(f"å…±æ‰¾åˆ° {total_count} ä¸ª{sector_type}æ¿å—")
        
        for index, row in sectors_df.iterrows():
            sector_code = row[code_col]
            sector_name = row[name_col]
            
            try:
                print(f"è¿›åº¦: {index + 1}/{total_count} - æ­£åœ¨è·å– {sector_name}({sector_code}) å†å²æ•°æ®...")
                
                # è·å–å†å²æ•°æ®
                historical_df = self.get_historical_sector_data_from_eastmoney(
                    sector_code=sector_code,
                    sector_type=sector_type,
                    trading_days=trading_days,
                    period=period,
                    is_incremental=is_incremental,
                    save_dir=save_dir if is_incremental else None
                )
                
                if not historical_df.empty:
                    # æ·»åŠ æ¿å—åç§°
                    historical_df['æ¿å—åç§°'] = sector_name
                    all_data[sector_code] = historical_df
                    successful_count += 1
                    
                    # ä¿å­˜å•ä¸ªæ¿å—æ•°æ®
                    if save_dir:
                        filename = f"{sector_name}({sector_code})_{period}_å†å²æ•°æ®.csv"
                        filepath = os.path.join(save_dir, filename)
                        historical_df.to_csv(filepath, index=False, encoding='utf-8-sig')
                        print(f"å·²ä¿å­˜: {filepath}")
                    
                else:
                    print(f"è­¦å‘Š: {sector_name}({sector_code}) æ— å†å²æ•°æ®")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.2)
                
            except Exception as e:
                print(f"é”™è¯¯: è·å– {sector_name}({sector_code}) æ•°æ®å¤±è´¥: {e}")
                continue
        
        print(f"\næ‰¹é‡è·å–å®Œæˆï¼æˆåŠŸ: {successful_count}/{total_count}")
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®å¹¶ä¿å­˜
        if all_data and save_dir:
            try:
                combined_df = pd.concat(all_data.values(), ignore_index=True)
                combined_filename = f"æ‰€æœ‰{sector_type}æ¿å—_{period}_å†å²æ•°æ®æ±‡æ€».csv"
                combined_filepath = os.path.join(save_dir, combined_filename)
                combined_df.to_csv(combined_filepath, index=False, encoding='utf-8-sig')
                print(f"å·²ä¿å­˜æ±‡æ€»æ–‡ä»¶: {combined_filepath} (å…± {len(combined_df)} æ¡è®°å½•)")
            except Exception as e:
                print(f"ä¿å­˜æ±‡æ€»æ–‡ä»¶å¤±è´¥: {e}")
        
        return all_data

class OptimizedCommonFunctions:
    """ä¼˜åŒ–åçš„é€šç”¨åŠŸèƒ½ç±»"""
    
    @staticmethod
    def get_file_list_in_directory(path: str, filetype: str = '.csv') -> List[str]:
        """
        è·å–æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰æŒ‡å®šç±»å‹çš„æ–‡ä»¶åˆ—è¡¨
        """
        file_list = []
        
        if not os.path.exists(path):
            print(f"ç›®å½•ä¸å­˜åœ¨: {path}")
            return file_list
        
        for root, dirs, files in os.walk(path):
            for file in files:
                if file.endswith(filetype):
                    file_list.append(file[:8] if len(file) >= 8 else file)
        
        return sorted(file_list)
    
    @staticmethod
    def batch_process_files(directory: str, process_func, filetype: str = '.csv'):
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶çš„é€šç”¨æ–¹æ³•
        """
        files = OptimizedCommonFunctions.get_file_list_in_directory(directory, filetype)
        
        results = []
        for file in files:
            try:
                result = process_func(os.path.join(directory, file))
                results.append(result)
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {file} å¤±è´¥: {e}")
        
        return results


# ä¸»è¦ä½¿ç”¨çš„ç±»å®ä¾‹
def get_stock_downloader():
    """è·å–è‚¡ç¥¨ä¸‹è½½å™¨å®ä¾‹"""
    return OptimizedDownloadStocksList()

def get_spider_client():
    """è·å–çˆ¬è™«å®¢æˆ·ç«¯å®ä¾‹"""
    return OptimizedSpiderFunc()

def get_common_functions():
    """è·å–é€šç”¨åŠŸèƒ½å®ä¾‹"""
    return OptimizedCommonFunctions()


if __name__ == '__main__':
    # ä½¿ç”¨ç¤ºä¾‹
    print("=== ä¼˜åŒ–ç‰ˆæœ¬ samequant_functions ===")
    
    # ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨
    downloader = get_stock_downloader()
    all_stocks = downloader.main()
    print(f"è·å–åˆ° {len(all_stocks)} åªè‚¡ç¥¨")
    exit()
    # è·å–å®æ—¶è¡Œæƒ…
    spider = get_spider_client()
    df = spider.get_realtime_market_data()
    print(f"è·å–å®æ—¶è¡Œæƒ…æ•°æ®: {len(df)} æ¡")
    
    # è·å–è¡Œä¸šæ•°æ®
    industry_df = spider.get_industry_data()
    print(f"è·å–è¡Œä¸šæ•°æ®: {len(industry_df)} æ¡")
    
    # è·å–æ¦‚å¿µæ•°æ®
    concept_df = spider.get_concept_data()
    print(f"è·å–æ¦‚å¿µæ•°æ®: {len(concept_df)} æ¡")