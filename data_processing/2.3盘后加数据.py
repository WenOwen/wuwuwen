# -*- coding: utf-8 -*-
"""
å¢é‡è¿½åŠ è‚¡ç¥¨å†å²æ•°æ®ï¼ˆä¸œæ–¹è´¢å¯Œæ•°æ®æºï¼‰
ä¼˜åŒ–ç‰ˆæœ¬ï¼šåªè·å–æœ€æ–°æ•°æ®åçš„å¢é‡æ•°æ®ï¼Œæé«˜æ•ˆç‡
"""

import time
import os
import pandas as pd
import datetime
from tqdm import tqdm
from samequant_functions_new import get_spider_client, OptimizedDownloadStocksList

pd.set_option('expand_frame_repr', False)  # å½“åˆ—å¤ªå¤šæ—¶ä¸æ¢è¡Œ
pd.set_option('display.max_rows', 6000)  # æœ€å¤šæ˜¾ç¤ºæ•°æ®çš„è¡Œæ•°
pd.set_option('display.float_format', lambda x: '%.2f' % x)  # ç¦ç”¨ç§‘å­¦è®¡æ•°æ³•


def get_latest_date_from_file(file_path):
    """
    ä»CSVæ–‡ä»¶ä¸­è·å–æœ€æ–°çš„äº¤æ˜“æ—¥æœŸ
    """
    try:
        if os.path.exists(file_path):
            df = pd.read_csv(file_path)
            if not df.empty and 'äº¤æ˜“æ—¥æœŸ' in df.columns:
                latest_date = df['äº¤æ˜“æ—¥æœŸ'].iloc[-1]
                return pd.to_datetime(latest_date).strftime('%Y-%m-%d')
        return None
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æœ€æ–°æ—¥æœŸå¤±è´¥ {file_path}: {e}")
        return None


def get_next_trading_date(date_str):
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
    """
    try:
        date_obj = pd.to_datetime(date_str)
        next_date = date_obj + datetime.timedelta(days=1)
        return next_date.strftime('%Y-%m-%d')
    except:
        return datetime.datetime.now().strftime('%Y-%m-%d')


def get_stock_list():
    """
    è·å–è‚¡ç¥¨åˆ—è¡¨
    """
    try:
        downloader = OptimizedDownloadStocksList()
        stock_list_path = downloader.all_stocklist_path
        
        if not os.path.exists(stock_list_path):
            print("âŒ è‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œè‚¡ç¥¨åˆ—è¡¨ä¸‹è½½")
            return pd.DataFrame()
        
        df_stocks = pd.read_csv(stock_list_path, dtype={'è‚¡ç¥¨ä»£ç ': str}, encoding='utf-8')
        return df_stocks
    except Exception as e:
        print(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame()


def add_to_stocks_history_data():
    """
    å¢é‡è¿½åŠ è‚¡ç¥¨å†å²æ•°æ®
    """
    print("ğŸ“ˆ å¼€å§‹å¢é‡è¿½åŠ è‚¡ç¥¨å†å²æ•°æ®...")
    start_time = time.time()
    
    try:
        # è·å–çˆ¬è™«å®¢æˆ·ç«¯å®ä¾‹
        spider = get_spider_client()
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        df_stocks = get_stock_list()
        if df_stocks.empty:
            print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
        
        total_stocks = len(df_stocks)
        print(f"ğŸ“Š å…±éœ€æ£€æŸ¥ {total_stocks} åªè‚¡ç¥¨çš„æ•°æ®")
        print("="*60)
        
        success_count = 0
        error_count = 0
        skip_count = 0
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=total_stocks, 
                   desc="å¢é‡æ›´æ–°è¿›åº¦", 
                   unit="åª",
                   bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] æˆåŠŸ:{postfix}",
                   ncols=80,
                   leave=True,
                   dynamic_ncols=False,
                   mininterval=1.0,
                   maxinterval=10.0)
        
        try:
            for i, row in df_stocks.iterrows():
                code = row['è‚¡ç¥¨ä»£ç ']
                
                try:
                    # æ„å»ºæ–‡ä»¶è·¯å¾„
                    his_path = os.path.join(spider.stock_hisdata_dir, f'{code}.csv')
                    
                    if os.path.exists(his_path):
                        # è·å–æ–‡ä»¶ä¸­çš„æœ€æ–°æ—¥æœŸ
                        latest_date = get_latest_date_from_file(his_path)
                        
                        if latest_date:
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆæœ€æ–°æ—¥æœŸæ˜¯å¦ä¸ºä»Šå¤©ä¹‹å‰ï¼‰
                            today = datetime.datetime.now().strftime('%Y-%m-%d')
                            if latest_date >= today:
                                skip_count += 1
                                pbar.update(1)
                                if i % 100 == 0:  # æ¯100ä¸ªè‚¡ç¥¨æ›´æ–°ä¸€æ¬¡æ˜¾ç¤º
                                    pbar.set_postfix_str(f"æˆåŠŸ:{success_count} è·³è¿‡:{skip_count}")
                                continue
                            
                            # è·å–å¢é‡å†å²æ•°æ®ï¼ˆä»æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹ï¼‰
                            df_new = spider.get_stock_history_data_with_real_market_cap(stock_code=code)
                            
                            if not df_new.empty:
                                # è¯»å–ç°æœ‰æ•°æ®
                                df_existing = pd.read_csv(his_path)
                                
                                # è¿‡æ»¤å‡ºæ–°æ•°æ®ï¼ˆæ—¥æœŸå¤§äºæœ€æ–°æ—¥æœŸçš„æ•°æ®ï¼‰
                                df_new['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df_new['äº¤æ˜“æ—¥æœŸ'])
                                latest_date_obj = pd.to_datetime(latest_date)
                                df_new_filtered = df_new[df_new['äº¤æ˜“æ—¥æœŸ'] > latest_date_obj]
                                
                                if not df_new_filtered.empty:
                                    # å°†æ—¥æœŸè½¬æ¢å›å­—ç¬¦ä¸²æ ¼å¼
                                    df_new_filtered['äº¤æ˜“æ—¥æœŸ'] = df_new_filtered['äº¤æ˜“æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
                                    
                                    # åˆå¹¶æ•°æ®
                                    df_combined = pd.concat([df_existing, df_new_filtered], ignore_index=True)
                                    
                                    # ä¿å­˜æ•°æ®
                                    df_combined.to_csv(his_path, index=False, encoding='utf-8')
                                    success_count += 1
                                    print(f"\nâœ… {code} æ–°å¢ {len(df_new_filtered)} æ¡æ•°æ®")
                                else:
                                    skip_count += 1
                            else:
                                skip_count += 1
                        else:
                            # æ–‡ä»¶å­˜åœ¨ä½†æ— æ³•è¯»å–æœ€æ–°æ—¥æœŸï¼Œé‡æ–°è·å–å®Œæ•´æ•°æ®
                            df_complete = spider.get_stock_history_data_with_real_market_cap(stock_code=code)
                            if not df_complete.empty:
                                df_complete.to_csv(his_path, index=False, encoding='utf-8')
                                success_count += 1
                                print(f"\nâœ… {code} é‡æ–°è·å–å®Œæ•´æ•°æ®")
                            else:
                                error_count += 1
                    else:
                        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·å–å®Œæ•´å†å²æ•°æ®
                        df_complete = spider.get_stock_history_data_with_real_market_cap(stock_code=code)
                        if not df_complete.empty:
                            # åˆ›å»ºç›®å½•
                            os.makedirs(os.path.dirname(his_path), exist_ok=True)
                            df_complete.to_csv(his_path, index=False, encoding='utf-8')
                            success_count += 1
                            print(f"\nâœ… {code} åˆ›å»ºå®Œæ•´å†å²æ•°æ®æ–‡ä»¶")
                        else:
                            error_count += 1
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡é¢‘
                    time.sleep(0.3)
                        
                except Exception as e:
                    error_count += 1
                    print(f"\nâŒ {code} å¤„ç†å‡ºé”™: {e}")
                
                # æ›´æ–°è¿›åº¦æ¡
                if i % 100 != 0:  # é¿å…é‡å¤æ›´æ–°
                    pbar.update(1)
                if i % 100 == 0 or success_count > 0:  # æ¯100ä¸ªæˆ–æœ‰æˆåŠŸæ›´æ–°æ—¶æ‰æ›´æ–°æ˜¾ç¤º
                    pbar.set_postfix_str(f"æˆåŠŸ:{success_count} è·³è¿‡:{skip_count}")
        
        finally:
            pbar.close()
        
        # è®¡ç®—æ€»è€—æ—¶
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ç»“æœ
        print("\n" + "="*60)
        print("ğŸ“Š å¢é‡æ›´æ–°å®Œæˆç»Ÿè®¡:")
        print(f"   âœ… æˆåŠŸæ›´æ–°: {success_count} åªè‚¡ç¥¨")
        print(f"   â­ï¸  è·³è¿‡æ›´æ–°: {skip_count} åªè‚¡ç¥¨")
        print(f"   âŒ æ›´æ–°å¤±è´¥: {error_count} åªè‚¡ç¥¨")
        print(f"   â±ï¸  æ€»è€—æ—¶: {format_time(total_time)}")
        print(f"   ğŸ“ æ•°æ®ä¿å­˜ç›®å½•: {spider.stock_hisdata_dir}")
        
        if success_count > 0:
            print(f"   ğŸ“ˆ å¹³å‡æ¯åªè‚¡ç¥¨è€—æ—¶: {total_time/total_stocks:.2f} ç§’")
            
        print("="*60)
        
        # æ›´æ–°æ¿å—æ•°æ®
        print("\n=== æ›´æ–°æ¿å—æ•°æ® ===")
        update_sector_data(spider)
        
        return success_count > 0
        
    except Exception as e:
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\nâŒ å¢é‡æ›´æ–°è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
        print(f"â±ï¸  è¿è¡Œæ—¶é—´: {format_time(total_time)}")
        print("\nğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        import traceback
        traceback.print_exc()
        return False


def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f} ç§’"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        remaining_seconds = seconds % 60
        return f"{minutes} åˆ† {remaining_seconds:.1f} ç§’"
    else:
        hours = int(seconds // 3600)
        remaining_minutes = int((seconds % 3600) // 60)
        remaining_seconds = seconds % 60
        return f"{hours} å°æ—¶ {remaining_minutes} åˆ† {remaining_seconds:.1f} ç§’"


def update_sector_data(spider):
    """
    æ›´æ–°æ¿å—æ•°æ®
    """
    file_full_dir = os.path.dirname(os.path.abspath(__file__))
    # ä¿®æ”¹ä¸ºdata/datas_emç›®å½•
    project_root = os.path.dirname(file_full_dir)
    datas_em_dir = os.path.join(project_root, 'data', 'datas_em')
    
    # è·å–è¡Œä¸šæ¿å—æ•°æ®
    df_industry = spider.get_industry_data(sort_field='f3')
    if not df_industry.empty:
        industry_path = os.path.join(datas_em_dir, 'è¡Œä¸šæ¿å—æ•°æ®.csv')
        df_industry.to_csv(industry_path, index=False, encoding='utf-8')
        print(f"âœ… è¡Œä¸šæ¿å—æ•°æ®å·²æ›´æ–°: {industry_path}")

    # è·å–æ¦‚å¿µæ¿å—æ•°æ®
    df_concept = spider.get_concept_data(sort_field='f3')
    if not df_concept.empty:
        concept_path = os.path.join(datas_em_dir, 'æ¦‚å¿µæ¿å—æ•°æ®.csv')
        df_concept.to_csv(concept_path, index=False, encoding='utf-8')
        print(f"âœ… æ¦‚å¿µæ¿å—æ•°æ®å·²æ›´æ–°: {concept_path}")


def main():
    """ä¸»å‡½æ•°ï¼šå¢é‡è¿½åŠ è‚¡ç¥¨å†å²æ•°æ®"""
    success = add_to_stocks_history_data()
    
    if success:
        print("ğŸ‰ å¢é‡è¿½åŠ è‚¡ç¥¨å†å²æ•°æ®ä»»åŠ¡å®Œæˆï¼")
    else:
        print("âš ï¸  å¢é‡è¿½åŠ ä»»åŠ¡æœªèƒ½æˆåŠŸå®Œæˆï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶")


if __name__ == '__main__':
    # äº¤æ˜“æ—¥ç›˜åè¿½åŠ å†å²è¡Œæƒ…æ•°æ®(å¢é‡æ›´æ–°æ¨¡å¼)
    main()

    # å®ç›˜æ—¶ï¼Œæ¯æ—¥15:31å®šæ—¶è¿è¡Œ
    import schedule
    schedule.every().day.at('15:31').do(add_to_stocks_history_data)