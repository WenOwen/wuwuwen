# -*- coding: utf-8 -*-
"""
å®Œæ•´è‚¡ç¥¨è®­ç»ƒè„šæœ¬ - ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨è¿›è¡Œå®Œæ•´è®­ç»ƒ
"""

import os
import sys
import logging
from datetime import datetime, timedelta

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from core.training_pipeline import ModelTrainingPipeline
from memory_monitor import MemoryMonitor, monitor_memory_during_training
import gc

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'complete_training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    """å®Œæ•´è®­ç»ƒä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´è‚¡ç¥¨è®­ç»ƒæµç¨‹")
    logger.info("=" * 80)
    
    # åˆå§‹åŒ–å†…å­˜ç›‘æ§
    memory_monitor = MemoryMonitor(warning_threshold=0.75, critical_threshold=0.85)
    memory_monitor.log_memory_status("è®­ç»ƒå¼€å§‹å‰")
    
    # åˆå§‹åŒ–è®­ç»ƒç®¡é“
    pipeline = ModelTrainingPipeline(
        data_dir="data/datas_em",  # æ˜ç¡®æŒ‡å®šä½¿ç”¨data/datas_emç›®å½•
        enable_batch_cache=False,  # å½»åº•ç¦ç”¨æ‰¹é‡ç¼“å­˜
        cache_workers=1  # ç¼“å­˜å·²ç¦ç”¨ï¼Œå·¥ä½œè¿›ç¨‹æ•°æ— æ•ˆ
    )
    
    # è·å–æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
    logger.info("ğŸ“Š æ‰«ææ‰€æœ‰å¯ç”¨è‚¡ç¥¨...")
    all_stocks = pipeline.get_available_stocks()  # ä¸é™åˆ¶æ•°é‡ï¼Œè·å–æ‰€æœ‰è‚¡ç¥¨
    
    if not all_stocks:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®")
        return
    
    logger.info(f"âœ… å‘ç° {len(all_stocks)} åªæœ‰æ•ˆè‚¡ç¥¨")
    logger.info(f"   å‰10åªè‚¡ç¥¨: {all_stocks[:10]}")
    
    # ç°åœ¨æœ‰äº†çœŸæ­£çš„åˆ†æ‰¹å¤„ç†ï¼Œå¯ä»¥å¤„ç†æ‰€æœ‰è‚¡ç¥¨
    logger.info(f"ğŸš€ ä½¿ç”¨åˆ†æ‰¹å¤„ç†æŠ€æœ¯ï¼Œå¯ä»¥å®‰å…¨å¤„ç†æ‰€æœ‰ {len(all_stocks)} åªè‚¡ç¥¨")
    logger.info("   - æ¯æ‰¹å¤„ç†50åªè‚¡ç¥¨ï¼Œé¿å…å†…å­˜æº¢å‡º")
    logger.info("   - æ¯åªè‚¡ç¥¨æœ€å¤š500ä¸ªæ ·æœ¬")
    logger.info("   - æ€»æ ·æœ¬æ•°é™åˆ¶50,000ä¸ª")
    logger.info("   - å›æœ›çª—å£å‡å°‘åˆ°30å¤©")
    
    memory_monitor.log_memory_status("è‚¡ç¥¨æ‰«æå®Œæˆ")
    
    # æ˜¾ç¤ºè®­ç»ƒé…ç½®
    logger.info("\nğŸ“‹ è®­ç»ƒé…ç½®:")
    logger.info(f"   è®­ç»ƒè½®æ¬¡: {pipeline.config['training_params']['epochs']}")
    logger.info(f"   æ‰¹æ¬¡å¤§å°: {pipeline.config['training_params']['batch_size']}")
    logger.info(f"   æ—©åœè½®æ¬¡: {pipeline.config['training_params']['early_stopping_patience']}")
    logger.info(f"   äº¤å‰éªŒè¯æŠ˜æ•°: {pipeline.config['training_params']['cv_folds']}")
    logger.info(f"   LightGBMæ ‘æ•°é‡: {pipeline.config['lightgbm_config']['n_estimators']}")
    logger.info(f"   é¢„æµ‹å¤©æ•°: {pipeline.config['prediction_days']}")
    logger.info(f"   æœ€å°æ ·æœ¬æ•°: {pipeline.config['min_samples']}")
    
    # è·³è¿‡ç¼“å­˜é¢„çƒ­ï¼ˆå·²ç¦ç”¨ç¼“å­˜ï¼‰
    logger.info("\nâš ï¸ ç¼“å­˜å·²ç¦ç”¨ï¼Œè·³è¿‡é¢„çƒ­æ­¥éª¤")
    warmup_time = timedelta(0)
    
    # æ‰¹é‡è®­ç»ƒæ‰€æœ‰é¢„æµ‹å¤©æ•°çš„æ¨¡å‹
    logger.info("\nğŸ¯ æ­¥éª¤2: å¼€å§‹æ‰¹é‡æ¨¡å‹è®­ç»ƒ...")
    start_training = datetime.now()
    
    try:
        # å†…å­˜ç›‘æ§ä¸‹çš„æ¨¡å‹è®­ç»ƒ
        memory_monitor.log_memory_status("å¼€å§‹æ¨¡å‹è®­ç»ƒ")
        
        # åªè®­ç»ƒä¸€ä¸ªé¢„æµ‹å¤©æ•°çš„æ¨¡å‹ä»¥èŠ‚çœå†…å­˜
        prediction_days_list = pipeline.config['prediction_days'][:1]  # åªå–ç¬¬ä¸€ä¸ªé¢„æµ‹å¤©æ•°
        logger.info(f"âš ï¸ ä¸ºèŠ‚çœå†…å­˜ï¼Œåªè®­ç»ƒ {prediction_days_list} å¤©é¢„æµ‹æ¨¡å‹")
        
        models = {}
        for prediction_days in prediction_days_list:
            logger.info(f"\nğŸ¯ è®­ç»ƒ {prediction_days} å¤©é¢„æµ‹æ¨¡å‹...")
            memory_monitor.log_memory_status(f"è®­ç»ƒ{prediction_days}å¤©æ¨¡å‹å‰")
            
            model = pipeline.train_model(
                stock_codes=all_stocks,
                prediction_days=prediction_days,
                use_hyperparameter_optimization=False,  # å…³é—­è¶…å‚æ•°ä¼˜åŒ–ä»¥èŠ‚çœæ—¶é—´å’Œå†…å­˜
                save_model=True,
                clear_cache=False
            )
            models[prediction_days] = model
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            memory_monitor.log_memory_status(f"è®­ç»ƒ{prediction_days}å¤©æ¨¡å‹å")
            
            # æ£€æŸ¥å†…å­˜çŠ¶æ€
            status = memory_monitor.check_memory_status()
            if status == "CRITICAL":
                logger.error("âŒ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œåœæ­¢è®­ç»ƒ")
                break
        
        total_training_time = datetime.now() - start_training
        
        # è®­ç»ƒç»“æœæ±‡æ€»
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ å®Œæ•´è®­ç»ƒæµç¨‹å®Œæˆï¼")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
        logger.info(f"   å¤„ç†è‚¡ç¥¨æ•°: {len(all_stocks)}")
        logger.info(f"   è®­ç»ƒæ¨¡å‹æ•°: {len(models)}/{len(pipeline.config['prediction_days'])}")
        logger.info(f"   æ¨¡å‹è®­ç»ƒæ—¶é—´: {total_training_time}")
        logger.info(f"   æ€»è€—æ—¶: {total_training_time}ï¼ˆæ— ç¼“å­˜é¢„çƒ­ï¼‰")
        
        # æ˜¾ç¤ºå„æ¨¡å‹æ€§èƒ½
        logger.info(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½æ±‡æ€»:")
        for prediction_days, model in models.items():
            logger.info(f"   {prediction_days}å¤©é¢„æµ‹æ¨¡å‹: å·²ä¿å­˜")
        
        # ç¼“å­˜å·²ç¦ç”¨ï¼Œæ— éœ€æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        logger.info(f"\nğŸ“Š ç¼“å­˜çŠ¶æ€: å·²ç¦ç”¨")
        
        # æ€§èƒ½å†å²
        summary = pipeline.get_performance_summary()
        if not summary.empty:
            logger.info(f"\nğŸ“‹ æ€§èƒ½å†å²æ‘˜è¦:")
            print(summary)
        
        logger.info(f"\nğŸ’¾ æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: {pipeline.model_dir}")
        logger.info(f"ğŸ“ è®­ç»ƒå®ŒæˆæŠ¥å‘Šå·²è‡ªåŠ¨ç”Ÿæˆåœ¨å„æ¨¡å‹ç›®å½•ä¸­")
        
        # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æ‘˜è¦
        memory_summary = memory_monitor.get_memory_summary()
        logger.info(f"\nğŸ“Š å†…å­˜ä½¿ç”¨æ‘˜è¦:")
        logger.info(f"   åˆå§‹å†…å­˜: {memory_summary['initial_mb']:.1f} MB")
        logger.info(f"   å½“å‰å†…å­˜: {memory_summary['current_mb']:.1f} MB")
        logger.info(f"   å³°å€¼å†…å­˜: {memory_summary['peak_mb']:.1f} MB")
        logger.info(f"   å†…å­˜å¢é•¿: {memory_summary['growth_mb']:.1f} MB")
        logger.info(f"   ç³»ç»Ÿä½¿ç”¨ç‡: {memory_summary['system_usage_percent']:.1f}%")
        
        # ä¼˜åŒ–å»ºè®®
        suggestions = memory_monitor.suggest_optimizations()
        if suggestions:
            logger.info(f"\nğŸ’¡ å†…å­˜ä¼˜åŒ–å»ºè®®:")
            for suggestion in suggestions:
                logger.info(f"   - {suggestion}")
        
        logger.info(f"âœ… å®Œæ•´è®­ç»ƒæµç¨‹æˆåŠŸå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ å®Œæ•´è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    else:
        print("\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
        sys.exit(1)