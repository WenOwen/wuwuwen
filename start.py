#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿ - ä¸€é”®å¯åŠ¨è„šæœ¬
åŠŸèƒ½ï¼šæ£€æŸ¥ç¯å¢ƒã€åˆå§‹åŒ–æ•°æ®ã€å¯åŠ¨æ‰€æœ‰æœåŠ¡
"""

import os
import sys
import subprocess
import time
import logging
import argparse
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    if sys.version_info < (3, 8):
        logger.error("Pythonç‰ˆæœ¬å¿…é¡»â‰¥3.8ï¼Œå½“å‰ç‰ˆæœ¬: %s", sys.version)
        return False
    logger.info("Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: %s", sys.version.split()[0])
    return True


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–åŒ…"""
    required_packages = [
        'pandas', 'numpy', 'sklearn', 'tensorflow', 
        'xgboost', 'streamlit', 'fastapi', 'uvicorn'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            logger.info("âœ“ %s å·²å®‰è£…", package)
        except ImportError:
            missing_packages.append(package)
            logger.warning("âœ— %s æœªå®‰è£…", package)
    
    if missing_packages:
        logger.error("ç¼ºå°‘ä¾èµ–åŒ…: %s", ', '.join(missing_packages))
        logger.info("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    logger.info("æ‰€æœ‰ä¾èµ–åŒ…æ£€æŸ¥é€šè¿‡")
    return True


def check_directories():
    """æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        'datas_em',
        'models', 
        'logs',
        'stockcode_list',
        'backup'
    ]
    
    for directory in directories:
        path = Path(directory)
        if not path.exists():
            path.mkdir(parents=True, exist_ok=True)
            logger.info("åˆ›å»ºç›®å½•: %s", directory)
        else:
            logger.info("âœ“ ç›®å½•å­˜åœ¨: %s", directory)
    
    return True


def check_data_files():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    data_dir = Path('datas_em')
    csv_files = list(data_dir.glob('*.csv'))
    
    if not csv_files:
        logger.warning("datas_emç›®å½•ä¸­æ²¡æœ‰è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
        logger.info("è¯·å…ˆè¿è¡Œæ•°æ®è·å–è„šæœ¬: python 2.1è·å–å…¨æ•°æ®ï¼ˆä¸œè´¢ï¼‰.py")
        return False
    
    logger.info("å‘ç° %d ä¸ªè‚¡ç¥¨æ•°æ®æ–‡ä»¶", len(csv_files))
    return True


def create_stock_list():
    """åˆ›å»ºé»˜è®¤è‚¡ç¥¨åˆ—è¡¨"""
    stock_list_file = Path('stockcode_list/all_stock_list.csv')
    
    if not stock_list_file.exists():
        logger.info("åˆ›å»ºé»˜è®¤è‚¡ç¥¨åˆ—è¡¨...")
        
        default_stocks = [
            ('sh600519', 'è´µå·èŒ…å°'),
            ('sz000001', 'å¹³å®‰é“¶è¡Œ'),
            ('sz000002', 'ä¸‡ç§‘A'),
            ('sh600036', 'æ‹›å•†é“¶è¡Œ'),
            ('sz000858', 'äº”ç²®æ¶²'),
            ('sh600000', 'æµ¦å‘é“¶è¡Œ'),
            ('sz000858', 'äº”ç²®æ¶²'),
            ('sh601318', 'ä¸­å›½å¹³å®‰'),
            ('sz002415', 'æµ·åº·å¨è§†'),
            ('sh600276', 'æ’ç‘åŒ»è¯')
        ]
        
        with open(stock_list_file, 'w', encoding='utf-8') as f:
            f.write('è‚¡ç¥¨ä»£ç ,è‚¡ç¥¨åç§°\n')
            for code, name in default_stocks:
                f.write(f'{code},{name}\n')
        
        logger.info("é»˜è®¤è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå®Œæˆ")
    
    return True


def check_redis():
    """æ£€æŸ¥RedisæœåŠ¡"""
    try:
        import redis
        r = redis.Redis(host='localhost', port=6379, decode_responses=True)
        r.ping()
        logger.info("âœ“ Redisè¿æ¥æ­£å¸¸")
        return True
    except Exception as e:
        logger.warning("Redisè¿æ¥å¤±è´¥: %s", str(e))
        logger.info("å°†ä½¿ç”¨å†…å­˜ç¼“å­˜æ›¿ä»£Redis")
        return False


def train_initial_models():
    """è®­ç»ƒåˆå§‹æ¨¡å‹"""
    logger.info("æ£€æŸ¥æ˜¯å¦å­˜åœ¨è®­ç»ƒå¥½çš„æ¨¡å‹...")
    
    models_dir = Path('models')
    model_folders = [d for d in models_dir.iterdir() if d.is_dir()]
    
    if not model_folders:
        logger.info("æœªå‘ç°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¼€å§‹è®­ç»ƒåˆå§‹æ¨¡å‹...")
        logger.warning("è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨è®­ç»ƒè„šæœ¬
            logger.info("ç”±äºé¦–æ¬¡è®­ç»ƒè€—æ—¶è¾ƒé•¿ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ:")
            logger.info("python training_pipeline.py")
            return False
        except Exception as e:
            logger.error("æ¨¡å‹è®­ç»ƒå¤±è´¥: %s", str(e))
            return False
    else:
        logger.info("å‘ç° %d ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹", len(model_folders))
        return True


def start_api_service():
    """å¯åŠ¨APIæœåŠ¡"""
    logger.info("å¯åŠ¨APIæœåŠ¡...")
    
    try:
        # å¯åŠ¨FastAPIæœåŠ¡
        cmd = [
            sys.executable, '-m', 'uvicorn',
            'prediction_service:app',
            '--host', '0.0.0.0',
            '--port', '8000',
            '--reload'
        ]
        
        logger.info("æ‰§è¡Œå‘½ä»¤: %s", ' '.join(cmd))
        process = subprocess.Popen(cmd)
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        time.sleep(3)
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸
        import requests
        try:
            response = requests.get('http://localhost:8000/', timeout=5)
            if response.status_code == 200:
                logger.info("âœ“ APIæœåŠ¡å¯åŠ¨æˆåŠŸ")
                return process
            else:
                logger.error("APIæœåŠ¡å“åº”å¼‚å¸¸: %s", response.status_code)
                return None
        except requests.exceptions.RequestException as e:
            logger.error("APIæœåŠ¡è¿æ¥å¤±è´¥: %s", str(e))
            return None
            
    except Exception as e:
        logger.error("å¯åŠ¨APIæœåŠ¡å¤±è´¥: %s", str(e))
        return None


def start_web_interface():
    """å¯åŠ¨Webç•Œé¢"""
    logger.info("å¯åŠ¨Streamlit Webç•Œé¢...")
    
    try:
        cmd = [
            sys.executable, '-m', 'streamlit', 'run',
            'streamlit_app.py',
            '--server.port', '8501',
            '--server.address', '0.0.0.0'
        ]
        
        logger.info("æ‰§è¡Œå‘½ä»¤: %s", ' '.join(cmd))
        process = subprocess.Popen(cmd)
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        time.sleep(5)
        
        logger.info("âœ“ Webç•Œé¢å¯åŠ¨æˆåŠŸ")
        logger.info("ğŸŒ è®¿é—®åœ°å€: http://localhost:8501")
        
        return process
        
    except Exception as e:
        logger.error("å¯åŠ¨Webç•Œé¢å¤±è´¥: %s", str(e))
        return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿå¯åŠ¨è„šæœ¬')
    parser.add_argument('--skip-checks', action='store_true', help='è·³è¿‡ç¯å¢ƒæ£€æŸ¥')
    parser.add_argument('--api-only', action='store_true', help='åªå¯åŠ¨APIæœåŠ¡')
    parser.add_argument('--web-only', action='store_true', help='åªå¯åŠ¨Webç•Œé¢')
    parser.add_argument('--no-models', action='store_true', help='è·³è¿‡æ¨¡å‹æ£€æŸ¥')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ å¼€å§‹å¯åŠ¨AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿ...")
    
    # ç¯å¢ƒæ£€æŸ¥
    if not args.skip_checks:
        logger.info("ğŸ“‹ è¿›è¡Œç¯å¢ƒæ£€æŸ¥...")
        
        if not check_python_version():
            sys.exit(1)
        
        if not check_dependencies():
            logger.error("âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥")
            sys.exit(1)
        
        if not check_directories():
            logger.error("âŒ ç›®å½•æ£€æŸ¥å¤±è´¥")
            sys.exit(1)
        
        create_stock_list()
        
        if not check_data_files():
            logger.warning("âš ï¸ æ•°æ®æ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        
        check_redis()
        
        if not args.no_models and not train_initial_models():
            logger.warning("âš ï¸ æ¨¡å‹æ£€æŸ¥å¤±è´¥ï¼Œé¢„æµ‹åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    
    # å¯åŠ¨æœåŠ¡
    processes = []
    
    if not args.web_only:
        logger.info("ğŸ”§ å¯åŠ¨APIæœåŠ¡...")
        api_process = start_api_service()
        if api_process:
            processes.append(api_process)
        else:
            logger.error("âŒ APIæœåŠ¡å¯åŠ¨å¤±è´¥")
            if not args.api_only:
                sys.exit(1)
    
    if not args.api_only:
        logger.info("ğŸŒ å¯åŠ¨Webç•Œé¢...")
        web_process = start_web_interface()
        if web_process:
            processes.append(web_process)
        else:
            logger.error("âŒ Webç•Œé¢å¯åŠ¨å¤±è´¥")
            sys.exit(1)
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    logger.info("ğŸ‰ ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼")
    logger.info("ğŸ“Š APIæ–‡æ¡£: http://localhost:8000/docs")
    logger.info("ğŸŒ Webç•Œé¢: http://localhost:8501")
    logger.info("ğŸ“ æŒ‰Ctrl+Cåœæ­¢æ‰€æœ‰æœåŠ¡")
    
    # ç­‰å¾…ç”¨æˆ·ä¸­æ–­
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢æœåŠ¡...")
        
        for process in processes:
            try:
                process.terminate()
                process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                process.kill()
                process.wait()
        
        logger.info("âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢")


if __name__ == "__main__":
    main()