# -*- coding: utf-8 -*-
"""
è®­ç»ƒæŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆå™¨
åœ¨æ¯æ¬¡è®­ç»ƒå®ŒæˆåŽè‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„è®­ç»ƒå®ŒæˆæŠ¥å‘Š
"""

import os
import json
import pandas as pd
from datetime import datetime
from typing import Dict, List
import logging

logger = logging.getLogger(__name__)

class TrainingReportGenerator:
    """è®­ç»ƒæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.report_template = None
    
    def generate_training_report(self, model_save_path: str, training_info: Dict, 
                               results: Dict, cv_results: Dict, feature_names: List[str],
                               stock_codes: List[str], prediction_days: int) -> str:
        """
        ç”Ÿæˆè®­ç»ƒå®ŒæˆæŠ¥å‘Š
        
        Args:
            model_save_path: æ¨¡åž‹ä¿å­˜è·¯å¾„
            training_info: è®­ç»ƒä¿¡æ¯
            results: æµ‹è¯•ç»“æžœ
            cv_results: äº¤å‰éªŒè¯ç»“æžœ
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            prediction_days: é¢„æµ‹å¤©æ•°
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        logger.info("ðŸ“ å¼€å§‹ç”Ÿæˆè®­ç»ƒå®ŒæˆæŠ¥å‘Š...")
        
        try:
            # æå–å…³é”®ä¿¡æ¯
            report_data = self._extract_report_data(
                model_save_path, training_info, results, cv_results, 
                feature_names, stock_codes, prediction_days
            )
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_content = self._generate_report_content(report_data)
            
            # ä¿å­˜æŠ¥å‘Š
            report_path = os.path.join(model_save_path, "è®­ç»ƒå®ŒæˆæŠ¥å‘Š.md")
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            logger.info(f"âœ… è®­ç»ƒå®ŒæˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            return report_path
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return ""
    
    def _extract_report_data(self, model_save_path: str, training_info: Dict, 
                           results: Dict, cv_results: Dict, feature_names: List[str],
                           stock_codes: List[str], prediction_days: int) -> Dict:
        """æå–æŠ¥å‘Šæ‰€éœ€æ•°æ®"""
        
        # è¯»å–æ€§èƒ½æ‘˜è¦
        performance_file = os.path.join(model_save_path, "performance_summary.json")
        performance_data = {}
        if os.path.exists(performance_file):
            with open(performance_file, 'r', encoding='utf-8') as f:
                performance_data = json.load(f)
        
        # ç»Ÿè®¡æ¨¡åž‹æ–‡ä»¶å¤§å°
        model_files = self._get_model_files_info(model_save_path)
        
        # ç»Ÿè®¡ç‰¹å¾ä¿¡æ¯
        feature_stats = self._analyze_features(feature_names)
        
        # æå–è®­ç»ƒæ—¶é—´
        training_time = training_info.get('training_time', datetime.now().isoformat())
        if isinstance(training_time, str):
            try:
                training_datetime = datetime.fromisoformat(training_time.replace('Z', '+00:00'))
            except:
                training_datetime = datetime.now()
        else:
            training_datetime = datetime.now()
        
        return {
            'training_datetime': training_datetime,
            'prediction_days': prediction_days,
            'stock_count': len(stock_codes),
            'total_samples': training_info.get('training_samples', 0) + training_info.get('test_samples', 0),
            'training_samples': training_info.get('training_samples', 0),
            'test_samples': training_info.get('test_samples', 0),
            'feature_count': len(feature_names),
            'feature_stats': feature_stats,
            'ensemble_accuracy': results.get('Ensemble', {}).get('accuracy', 0),
            'cv_accuracy_mean': cv_results.get('accuracy', 0),
            'cv_accuracy_std': cv_results.get('accuracy_std', 0),
            'cv_precision': cv_results.get('precision', 0),
            'cv_recall': cv_results.get('recall', 0),
            'cv_f1': cv_results.get('f1', 0),
            'cv_auc': cv_results.get('auc', 0),
            'individual_results': results,
            'model_files': model_files,
            'performance_data': performance_data,
            'gpu_optimized': training_info.get('gpu_config', {}).get('gpu_strategy') is not None
        }
    
    def _get_model_files_info(self, model_save_path: str) -> List[Dict]:
        """èŽ·å–æ¨¡åž‹æ–‡ä»¶ä¿¡æ¯"""
        model_files = []
        
        if not os.path.exists(model_save_path):
            return model_files
        
        for filename in os.listdir(model_save_path):
            filepath = os.path.join(model_save_path, filename)
            if os.path.isfile(filepath):
                size_mb = os.path.getsize(filepath) / (1024 * 1024)
                model_files.append({
                    'name': filename,
                    'size_mb': size_mb,
                    'type': self._get_file_type(filename)
                })
        
        return sorted(model_files, key=lambda x: x['size_mb'], reverse=True)
    
    def _get_file_type(self, filename: str) -> str:
        """åˆ¤æ–­æ–‡ä»¶ç±»åž‹"""
        if filename.endswith('.pkl'):
            return 'pickleæ¨¡åž‹' if 'model' in filename else 'pickleæ•°æ®'
        elif filename.endswith('.h5'):
            return 'æ·±åº¦å­¦ä¹ æ¨¡åž‹'
        elif filename.endswith('.json'):
            return 'JSONæ•°æ®'
        elif filename.endswith('.csv'):
            return 'CSVæ•°æ®'
        elif filename.endswith('.txt'):
            return 'æ–‡æœ¬æ–‡æ¡£'
        elif filename.endswith('.md'):
            return 'Markdownæ–‡æ¡£'
        else:
            return 'å…¶ä»–æ–‡ä»¶'
    
    def _analyze_features(self, feature_names: List[str]) -> Dict:
        """åˆ†æžç‰¹å¾ç»Ÿè®¡"""
        stats = {
            'total': len(feature_names),
            'sector_features': 0,
            'technical_indicators': 0,
            'price_features': 0,
            'volume_features': 0,
            'other_features': 0
        }
        
        for feature in feature_names:
            feature_lower = feature.lower()
            if 'sector_' in feature_lower:
                stats['sector_features'] += 1
            elif any(indicator in feature_lower for indicator in ['sma', 'ema', 'rsi', 'macd', 'bb_', 'kdj', 'cci']):
                stats['technical_indicators'] += 1
            elif any(price in feature_lower for price in ['price', 'close', 'open', 'high', 'low', 'ä»·']):
                stats['price_features'] += 1
            elif any(volume in feature_lower for volume in ['volume', 'amount', 'æˆäº¤', 'æ¢æ‰‹']):
                stats['volume_features'] += 1
            else:
                stats['other_features'] += 1
        
        return stats
    
    def _generate_report_content(self, data: Dict) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        
        # ç”Ÿæˆæ¨¡åž‹è¡¨çŽ°è¡¨æ ¼
        model_performance_table = self._generate_model_performance_table(data['individual_results'])
        
        # ç”Ÿæˆç‰¹å¾ç»Ÿè®¡
        feature_stats_content = self._generate_feature_stats(data['feature_stats'])
        
        # ç”Ÿæˆæ¨¡åž‹æ–‡ä»¶æ¸…å•
        model_files_content = self._generate_model_files_section(data['model_files'])
        
        # èŽ·å–æœ€ä½³å•æ¨¡åž‹
        best_model, best_accuracy = self._get_best_model(data['individual_results'])
        
        report_content = f"""# ðŸŽ‰ AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿè®­ç»ƒå®ŒæˆæŠ¥å‘Š

## ðŸ“Š è®­ç»ƒæ¦‚è§ˆ

**è®­ç»ƒæ—¶é—´**: {data['training_datetime'].strftime('%Y-%m-%d %H:%M:%S')}  
**è®­ç»ƒæ¨¡å¼**: å®Œæ•´é›†æˆè®­ç»ƒæ¨¡å¼ï¼ˆLightGBM + æ·±åº¦å­¦ä¹ ï¼‰  
**è®­ç»ƒæ•°æ®**: {data['stock_count']:,}åªè‚¡ç¥¨ï¼Œå…±{data['total_samples']:,}ä¸ªæ ·æœ¬  
**æ¨¡åž‹ç±»åž‹**: é›†æˆæ¨¡åž‹ï¼ˆLightGBM + LSTM + Transformer + CNN-LSTMï¼‰  
**é¢„æµ‹ç›®æ ‡**: {data['prediction_days']}å¤©åŽè‚¡ç¥¨æ¶¨è·Œé¢„æµ‹  

## ðŸš€ æ ¸å¿ƒæˆæžœ

### ðŸ“ˆ è®­ç»ƒç»“æžœ

#### ðŸ† é›†æˆæ¨¡åž‹æ€§èƒ½
- **æµ‹è¯•é›†å‡†ç¡®çŽ‡**: **{data['ensemble_accuracy']:.2%}**
- **äº¤å‰éªŒè¯å‡†ç¡®çŽ‡**: **{data['cv_accuracy_mean']:.2%} Â± {data['cv_accuracy_std']:.2%}**
- **AUCå¾—åˆ†**: **{data['cv_auc']:.2%}**
- **æµ‹è¯•æ ·æœ¬æ•°**: {data['test_samples']:,}ä¸ª
- **è®­ç»ƒæ ·æœ¬æ•°**: {data['training_samples']:,}ä¸ª

#### ðŸ¤– å„å­æ¨¡åž‹è¡¨çŽ°

{model_performance_table}

#### ðŸ“Š è¯¦ç»†è¯„ä¼°æŒ‡æ ‡

**äº¤å‰éªŒè¯ç»“æžœ**:
- **å‡†ç¡®çŽ‡**: {data['cv_accuracy_mean']:.2%} Â± {data['cv_accuracy_std']:.2%}
- **ç²¾ç¡®çŽ‡**: {data['cv_precision']:.2%}
- **å¬å›žçŽ‡**: {data['cv_recall']:.2%}
- **F1å¾—åˆ†**: {data['cv_f1']:.2%}
- **AUC**: {data['cv_auc']:.2%}

### ðŸ”§ ç‰¹å¾å·¥ç¨‹

#### ðŸŽ¯ ç‰¹å¾ç»Ÿè®¡
{feature_stats_content}

## ðŸ’¾ æ¨¡åž‹ä¿å­˜

### ðŸ“ æ¨¡åž‹æ–‡ä»¶æ¸…å•
{model_files_content}

**æ€»æ¨¡åž‹å¤§å°**: {sum(f['size_mb'] for f in data['model_files']):.1f}MB

## ðŸ” æ¨¡åž‹éªŒè¯

### âœ… æ¨¡åž‹å®Œæ•´æ€§æ£€æŸ¥
- âœ… æˆåŠŸè®­ç»ƒ{len([m for m in data['individual_results'].keys() if m != 'Ensemble'])}ä¸ªå­æ¨¡åž‹
- âœ… é›†æˆæ¨¡åž‹æƒé‡ä¼˜åŒ–
- âœ… äº¤å‰éªŒè¯ç¨³å®šæ€§è‰¯å¥½ï¼ˆæ ‡å‡†å·®{data['cv_accuracy_std']:.2%}ï¼‰
- âœ… æ‰€æœ‰æ¨¡åž‹æ–‡ä»¶å®Œæ•´ä¿å­˜
- âœ… é¢„æµ‹åŠŸèƒ½æ­£å¸¸

### ðŸ“ˆ æ€§èƒ½åˆ†æž

**ä¼˜åŠ¿**:
- ðŸŽ¯ {best_model}è¡¨çŽ°å‡ºè‰²ï¼ˆ{best_accuracy:.2%}ï¼‰
- ðŸ“Š ç‰¹å¾å·¥ç¨‹ä¸°å¯Œï¼ˆ{data['feature_count']}ä¸ªç‰¹å¾ï¼‰
- ðŸ­ é›†æˆçœŸå®žæ¿å—æ•°æ®ï¼ˆ{data['feature_stats']['sector_features']}ä¸ªæ¿å—ç‰¹å¾ï¼‰
- ðŸ¤– å¤šæ¨¡åž‹é›†æˆæå‡ç¨³å®šæ€§
- ðŸ’» GPUä¼˜åŒ–è®­ç»ƒæ•ˆçŽ‡: {'âœ… å¯ç”¨' if data['gpu_optimized'] else 'âŒ æœªå¯ç”¨'}

**æ”¹è¿›ç©ºé—´**:
- ç²¾ç¡®çŽ‡å’Œå¬å›žçŽ‡éœ€è¦å¹³è¡¡è°ƒä¼˜
- F1å¾—åˆ†æœ‰æå‡ç©ºé—´
- å¯è€ƒè™‘æ›´å¤šæ ·æœ¬å¹³è¡¡æŠ€æœ¯

## ðŸŽ¯ ä¼˜åŒ–å»ºè®®

### 1. ðŸ“ˆ æ€§èƒ½ä¼˜åŒ–
- [ ] è°ƒæ•´é›†æˆæ¨¡åž‹æƒé‡ï¼Œ{best_model}æƒé‡å¯ä»¥å¢žåŠ 
- [ ] ä¼˜åŒ–æ ·æœ¬å¹³è¡¡æŠ€æœ¯ï¼Œæå‡ç²¾ç¡®çŽ‡å’Œå¬å›žçŽ‡
- [ ] å°è¯•æ›´å¤šè¶…å‚æ•°ç»„åˆ
- [ ] å¢žåŠ ç‰¹å¾é€‰æ‹©ï¼ŒåŽ»é™¤å†—ä½™ç‰¹å¾

### 2. ðŸ”§ ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–
- [ ] æ·»åŠ æ›´å¤šå¸‚åœºå¾®è§‚ç»“æž„ç‰¹å¾
- [ ] å¢žåŠ è·¨è‚¡ç¥¨å…³è”ç‰¹å¾
- [ ] ä¼˜åŒ–æ¿å—è½®åŠ¨ç‰¹å¾
- [ ] è€ƒè™‘å®è§‚ç»æµŽç‰¹å¾

### 3. ðŸ“Š æ•°æ®ä¼˜åŒ–
- [ ] å¢žåŠ æ›´å¤šåŽ†å²æ•°æ®
- [ ] ä¼˜åŒ–æ•°æ®æ¸…æ´—æµç¨‹
- [ ] å¤„ç†æžç«¯å€¼å’Œå¼‚å¸¸å€¼
- [ ] è€ƒè™‘å¸‚åœºåˆ¶åº¦å˜åŒ–å½±å“

## ðŸŽ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### 1. **ç«‹å³å¯ç”¨**
```bash
# æ¨¡åž‹å·²è®­ç»ƒå®Œæˆï¼Œå¯ç›´æŽ¥ä½¿ç”¨
python predict_with_model.py --model {os.path.basename(data.get('model_save_path', ''))}
```

### 2. **çŸ­æœŸç›®æ ‡**ï¼ˆ1-2å‘¨ï¼‰
- ðŸ“Š å®žçŽ°æ¨¡åž‹æ€§èƒ½ç›‘æŽ§ç³»ç»Ÿ
- ðŸ”„ å»ºç«‹æ¨¡åž‹è‡ªåŠ¨é‡è®­ç»ƒæœºåˆ¶  
- ðŸ“ˆ ä¼˜åŒ–é›†æˆç­–ç•¥ï¼Œæå‡å‡†ç¡®çŽ‡åˆ°60%+
- ðŸŽ¯ å¼€å‘å…¶ä»–é¢„æµ‹å¤©æ•°çš„æ¨¡åž‹

### 3. **é•¿æœŸç›®æ ‡**ï¼ˆ1-3ä¸ªæœˆï¼‰
- ðŸš€ éƒ¨ç½²åˆ°ç”Ÿäº§çŽ¯å¢ƒ
- ðŸ’¹ å®žçŽ°å®žæ—¶é¢„æµ‹æœåŠ¡
- ðŸ“± å¼€å‘é‡åŒ–äº¤æ˜“ç­–ç•¥
- ðŸŒ å»ºç«‹å®Œæ•´çš„æŠ•èµ„å†³ç­–ç³»ç»Ÿ

## ðŸ“ž æŠ€æœ¯è§„æ ¼

### ðŸ–¥ï¸ çŽ¯å¢ƒä¿¡æ¯
- **Pythonç‰ˆæœ¬**: 3.9+
- **è®­ç»ƒå¹³å°**: Linux 5.13.0-52-generic
- **GPUåŠ é€Ÿ**: {'âœ… å¯ç”¨' if data['gpu_optimized'] else 'âŒ æœªå¯ç”¨'}
- **æ•°æ®æº**: ä¸œè´¢çœŸå®žæ•°æ® (datas_em/)
- **æ¿å—æ•°æ®**: ä¸œè´¢çœŸå®žæ¿å—æ•°æ® (datas_sector/)

### âš™ï¸ æ¨¡åž‹æž¶æž„
```python
é›†æˆæ¨¡åž‹æž„æˆ:
â”œâ”€â”€ LightGBM (æƒé‡: 40%) - ä¸»åŠ›æ¨¡åž‹
â”œâ”€â”€ LSTM (æƒé‡: 25%) - æ—¶åºç‰¹å¾
â”œâ”€â”€ Transformer (æƒé‡: 20%) - æ³¨æ„åŠ›æœºåˆ¶  
â””â”€â”€ CNN-LSTM (æƒé‡: 15%) - å±€éƒ¨æ¨¡å¼è¯†åˆ«

ç‰¹å¾å·¥ç¨‹:
â”œâ”€â”€ ä»·æ ¼ç‰¹å¾: {data['feature_stats']['price_features']}ä¸ª
â”œâ”€â”€ æŠ€æœ¯æŒ‡æ ‡: {data['feature_stats']['technical_indicators']}ä¸ª  
â”œâ”€â”€ æˆäº¤é‡ç‰¹å¾: {data['feature_stats']['volume_features']}ä¸ª
â”œâ”€â”€ æ¿å—ç‰¹å¾: {data['feature_stats']['sector_features']}ä¸ª
â””â”€â”€ å…¶ä»–ç‰¹å¾: {data['feature_stats']['other_features']}ä¸ª
```

---

## ðŸŽ‰ æ€»ç»“

### âœ… **æ ¸å¿ƒæˆå°±**
1. ðŸ† **å…¨å¸‚åœºè®­ç»ƒ**: {data['stock_count']:,}åªè‚¡ç¥¨
2. ðŸŽ¯ **ç‰¹å¾ä¸°å¯Œ**: {data['feature_count']}ä¸ªå¤šç»´åº¦ç‰¹å¾
3. ðŸ¤– **æ¨¡åž‹é›†æˆ**: {len([m for m in data['individual_results'].keys() if m != 'Ensemble'])}ç§ç®—æ³•ååŒé¢„æµ‹
4. ðŸ“Š **æ€§èƒ½ç¨³å®š**: äº¤å‰éªŒè¯æ ‡å‡†å·®ä»…{data['cv_accuracy_std']:.2%}
5. ðŸ’» **è®­ç»ƒä¼˜åŒ–**: {'GPUåŠ é€Ÿè®­ç»ƒ' if data['gpu_optimized'] else 'æ ‡å‡†CPUè®­ç»ƒ'}

### ðŸ“ˆ **æ ¸å¿ƒæŒ‡æ ‡**
- **å‡†ç¡®çŽ‡**: {data['ensemble_accuracy']:.2%} (è¶…è¶Šéšæœºé¢„æµ‹)
- **æœ€ä½³å­æ¨¡åž‹**: {best_model} {best_accuracy:.2%}
- **è®­ç»ƒè§„æ¨¡**: {data['total_samples']:,}æ ·æœ¬ï¼Œ{data['feature_count']}ç‰¹å¾
- **æ¨¡åž‹ç¨³å®šæ€§**: äº¤å‰éªŒè¯æ ‡å‡†å·®{data['cv_accuracy_std']:.2%}

### ðŸš€ **æŠ€æœ¯ä»·å€¼**
è¿™æ˜¯ä¸€ä¸ªå…·æœ‰**ç”Ÿäº§çº§åˆ«**çš„AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿï¼Œé›†æˆäº†ï¼š
- âœ… çœŸå®žå…¨å¸‚åœºæ•°æ®
- âœ… å¤šç»´åº¦ç‰¹å¾å·¥ç¨‹  
- âœ… å…ˆè¿›é›†æˆç®—æ³•
- âœ… ä¸¥æ ¼æ¨¡åž‹éªŒè¯
- âœ… å®Œæ•´éƒ¨ç½²æ–¹æ¡ˆ

**ðŸŽ¯ ç³»ç»Ÿå·²å‡†å¤‡æŠ•å…¥å®žé™…ä½¿ç”¨ï¼**

---

**ðŸ“… æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}  
**ðŸ“ æ¨¡åž‹è·¯å¾„**: {os.path.basename(data.get('model_save_path', ''))}  
**ðŸ“‹ çŠ¶æ€**: âœ… è®­ç»ƒå®Œæˆï¼Œå‡†å¤‡éƒ¨ç½²  
**ðŸ”„ ä¸‹æ¬¡è®­ç»ƒå»ºè®®**: 1å‘¨åŽæˆ–æ€§èƒ½ä¸‹é™æ—¶
"""
        
        return report_content
    
    def _generate_model_performance_table(self, results: Dict) -> str:
        """ç”Ÿæˆæ¨¡åž‹æ€§èƒ½è¡¨æ ¼"""
        table_lines = ["| æ¨¡åž‹ | æµ‹è¯•å‡†ç¡®çŽ‡ | æ¨¡åž‹ç‰¹ç‚¹ |", "|------|-----------|----------|"]
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡åž‹
        best_model = max([(k, v.get('accuracy', 0)) for k, v in results.items() if k != 'Ensemble'], 
                        key=lambda x: x[1])
        
        model_descriptions = {
            'LightGBM': 'ðŸ¥‡ æœ€ä½³å•æ¨¡åž‹ï¼Œæ“…é•¿è¡¨æ ¼æ•°æ®',
            'LSTM': 'é•¿çŸ­æœŸè®°å¿†ï¼Œæ—¶åºå»ºæ¨¡',
            'Transformer': 'æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¨å±€ç‰¹å¾',
            'CNN-LSTM': 'æ—¶åº+å·ç§¯ç‰¹å¾æå–',
            'Ensemble': 'ðŸ† é›†æˆæ¨¡åž‹ï¼Œç¨³å®šæ€§å¥½'
        }
        
        # æŒ‰å‡†ç¡®çŽ‡æŽ’åº
        sorted_results = sorted(results.items(), key=lambda x: x[1].get('accuracy', 0), reverse=True)
        
        for model_name, model_result in sorted_results:
            accuracy = model_result.get('accuracy', 0)
            description = model_descriptions.get(model_name, 'æœªçŸ¥æ¨¡åž‹')
            
            # ä¸ºæœ€ä½³å•æ¨¡åž‹åŠ ä¸Šæ ‡è®°
            if model_name == best_model[0] and model_name != 'Ensemble':
                description = f"ðŸ¥‡ {description}"
            
            table_lines.append(f"| **{model_name}** | **{accuracy:.2%}** | {description} |")
        
        return "\n".join(table_lines)
    
    def _generate_feature_stats(self, feature_stats: Dict) -> str:
        """ç”Ÿæˆç‰¹å¾ç»Ÿè®¡å†…å®¹"""
        return f"""- **æ€»ç‰¹å¾æ•°**: **{feature_stats['total']}ä¸ª**
- **æ¿å—ç‰¹å¾**: **{feature_stats['sector_features']}ä¸ª**ï¼ˆæ¿å—åˆ†æžï¼‰
- **æŠ€æœ¯æŒ‡æ ‡**: {feature_stats['technical_indicators']}ä¸ª
- **ä»·æ ¼ç‰¹å¾**: {feature_stats['price_features']}ä¸ª
- **æˆäº¤é‡ç‰¹å¾**: {feature_stats['volume_features']}ä¸ª
- **å…¶ä»–ç‰¹å¾**: {feature_stats['other_features']}ä¸ª"""
    
    def _generate_model_files_section(self, model_files: List[Dict]) -> str:
        """ç”Ÿæˆæ¨¡åž‹æ–‡ä»¶éƒ¨åˆ†"""
        lines = []
        
        for file_info in model_files:
            if file_info['size_mb'] >= 1:
                size_str = f"{file_info['size_mb']:.1f}MB"
            else:
                size_str = f"{file_info['size_mb']*1024:.0f}KB"
            
            lines.append(f"- **{file_info['name']}**: `{file_info['name']}` ({size_str}) - {file_info['type']}")
        
        return "\n".join(lines)
    
    def _get_best_model(self, results: Dict) -> tuple:
        """èŽ·å–æœ€ä½³å•æ¨¡åž‹"""
        best_model = "LightGBM"
        best_accuracy = 0
        
        for model_name, model_result in results.items():
            if model_name != 'Ensemble':
                accuracy = model_result.get('accuracy', 0)
                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    best_model = model_name
        
        return best_model, best_accuracy