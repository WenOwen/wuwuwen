#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿ - LightGBMå®Œæ•´è®­ç»ƒè„šæœ¬
åŠŸèƒ½ï¼šå¯åŠ¨åŒ…å«LightGBMçš„å®Œæ•´è®­ç»ƒæµç¨‹
"""

import os
import sys
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
import joblib
from datetime import datetime, timedelta
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'core'))
sys.path.insert(0, os.path.join(project_root, 'utils'))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('training.log')
    ]
)
logger = logging.getLogger(__name__)

def check_data_directory():
    """æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨"""
    data_dirs = ['datas_em', 'datas_index', 'financial_csv']
    
    for data_dir in data_dirs:
        if os.path.exists(data_dir):
            csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
            if csv_files:
                logger.info(f"å‘ç°æ•°æ®ç›®å½• {data_dir}ï¼ŒåŒ…å« {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
                return data_dir, csv_files[:5]  # è¿”å›å‰5ä¸ªæ–‡ä»¶ä½œä¸ºæµ‹è¯•
    
    logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®ç›®å½•ï¼")
    return None, []

def fix_lightgbm_setup():
    """ä¿®å¤LightGBMè®¾ç½®"""
    try:
        import lightgbm as lgb
        logger.info(f"âœ… LightGBMç‰ˆæœ¬: {lgb.__version__}")
        
        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        from sklearn.datasets import make_classification
        X, y = make_classification(n_samples=100, n_features=10, random_state=42)
        
        model = lgb.LGBMClassifier(
            objective='binary',
            n_estimators=10,
            verbose=-1,
            random_state=42
        )
        model.fit(X, y)
        logger.info("âœ… LightGBMåŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ LightGBMè®¾ç½®å¤±è´¥: {str(e)}")
        return False

def simplified_training():
    """ç®€åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œä¸“æ³¨äºLightGBM"""
    logger.info("ğŸš€ å¼€å§‹ç®€åŒ–ç‰ˆLightGBMè®­ç»ƒ...")
    
    # æ£€æŸ¥æ•°æ®
    data_dir, sample_files = check_data_directory()
    if not data_dir:
        return False
    
    # é€‰æ‹©ä¸€ä¸ªæœ‰æ•°æ®çš„è‚¡ç¥¨æ–‡ä»¶è¿›è¡Œè®­ç»ƒ
    for file_name in sample_files:
        try:
            file_path = os.path.join(data_dir, file_name)
            df = pd.read_csv(file_path)
            
            if len(df) < 100:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®
                continue
                
            logger.info(f"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {file_name}, æ•°æ®é‡: {len(df)}")
            
            # ç®€å•çš„ç‰¹å¾å·¥ç¨‹
            if 'æ”¶ç›˜ä»·' in df.columns or 'close' in df.columns:
                close_col = 'æ”¶ç›˜ä»·' if 'æ”¶ç›˜ä»·' in df.columns else 'close'
                
                # åˆ›å»ºåŸºæœ¬ç‰¹å¾
                df['price_change'] = df[close_col].pct_change()
                df['price_ma5'] = df[close_col].rolling(5).mean()
                df['price_ma10'] = df[close_col].rolling(10).mean()
                
                # åˆ›å»ºæ ‡ç­¾ï¼ˆç¬¬äºŒå¤©æ¶¨è·Œï¼‰
                df['target'] = (df[close_col].shift(-1) > df[close_col]).astype(int)
                
                # å‡†å¤‡è®­ç»ƒæ•°æ®
                feature_cols = ['price_change', 'price_ma5', 'price_ma10']
                df_clean = df[feature_cols + ['target']].dropna()
                
                if len(df_clean) < 50:
                    continue
                
                X = df_clean[feature_cols]
                y = df_clean['target']
                
                # åˆ†å‰²æ•°æ®
                split_idx = int(len(X) * 0.8)
                X_train, X_test = X[:split_idx], X[split_idx:]
                y_train, y_test = y[:split_idx], y[split_idx:]
                
                # è®­ç»ƒLightGBMæ¨¡å‹
                import lightgbm as lgb
                
                model = lgb.LGBMClassifier(
                    objective='binary',
                    n_estimators=100,
                    learning_rate=0.1,
                    max_depth=6,
                    random_state=42,
                    verbose=-1
                )
                
                logger.info("ğŸ”„ å¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹...")
                model.fit(X_train, y_train)
                
                # é¢„æµ‹å’Œè¯„ä¼°
                from sklearn.metrics import accuracy_score, classification_report
                
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                
                logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼")
                logger.info(f"ğŸ“Š æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
                logger.info(f"ğŸ“Š åˆ†ç±»æŠ¥å‘Š:\n{classification_report(y_test, y_pred)}")
                
                # ä¿å­˜æ¨¡å‹
                os.makedirs('models', exist_ok=True)
                model_path = f'models/lightgbm_model_{file_name.replace(".csv", "")}.pkl'
                joblib.dump(model, model_path)
                logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
                
                return True
                
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {str(e)}")
            continue
    
    logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„è®­ç»ƒæ•°æ®")
    return False

def full_training_pipeline():
    """å®Œæ•´çš„è®­ç»ƒæµæ°´çº¿"""
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´è®­ç»ƒæµæ°´çº¿...")
    
    try:
        # å¯¼å…¥è®­ç»ƒæ¨¡å—
        from core.training_pipeline import ModelTrainingPipeline
        
        # ä¿®å¤å¯¼å…¥è·¯å¾„é—®é¢˜
        import sys
        sys.path.append('core')
        sys.path.append('utils')
        
        # åˆ›å»ºè®­ç»ƒç®¡é“
        pipeline = ModelTrainingPipeline()
        
        # æ£€æŸ¥æ•°æ®
        data_dir, sample_files = check_data_directory()
        if not data_dir:
            return simplified_training()
        
        # æå–è‚¡ç¥¨ä»£ç 
        stock_codes = [f.replace('.csv', '') for f in sample_files]
        logger.info(f"å‡†å¤‡è®­ç»ƒè‚¡ç¥¨: {stock_codes}")
        
        # å¼€å§‹è®­ç»ƒ
        model = pipeline.train_model(
            stock_codes=stock_codes,
            prediction_days=1,
            use_hyperparameter_optimization=False,  # å…ˆä¸ç”¨è¶…å‚æ•°ä¼˜åŒ–ï¼ŒåŠ å¿«è®­ç»ƒ
            save_model=True
        )
        
        logger.info("âœ… å®Œæ•´è®­ç»ƒæµç¨‹å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"å®Œæ•´è®­ç»ƒæµç¨‹å¤±è´¥: {str(e)}")
        logger.info("ğŸ”„ åˆ‡æ¢åˆ°ç®€åŒ–è®­ç»ƒæ¨¡å¼...")
        return simplified_training()

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ¤– AIè‚¡å¸‚é¢„æµ‹ç³»ç»Ÿ - LightGBMè®­ç»ƒå¯åŠ¨")
    logger.info("=" * 60)
    
    # 1. æ£€æŸ¥LightGBM
    if not fix_lightgbm_setup():
        logger.error("âŒ LightGBMè®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return
    
    # 2. å°è¯•å®Œæ•´è®­ç»ƒæµç¨‹
    try:
        success = full_training_pipeline()
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")
        success = False
    
    if success:
        logger.info("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    else:
        logger.info("âš ï¸ è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    logger.info("=" * 60)

if __name__ == "__main__":
    main()